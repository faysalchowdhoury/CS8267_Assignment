{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67dc9bc0-7f5b-4726-92af-c5ee96377b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "from getpass import getpass\n",
    "HUGGINGFACEHUB_API_TOKEN =getpass()\n",
    "#Faysal's HuggingFace testtoken: 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\n",
    "#My HuggingFace testtoken: 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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75a8664a-349e-4d40-a6da-5c75bc7f446e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thema\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\thema\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "C:\\Users\\thema\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.23-246-g3d31191b-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os. environ[\"HUGGINGFACEHUB_API_TOKEN\"] = HUGGINGFACEHUB_API_TOKEN\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3073e78-2bf3-4f84-9556-0fc7b90d4b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import HuggingFaceHub\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "#Load and analyze multiple documents from the web\n",
    "\n",
    "#old line of code, originally tried research articles from arxiv, but sites like this have measures to prevent automated scraping without proper identification\n",
    "#loader = WebBaseLoader([\"https://arxiv.org/pdf/1908.08345.pdf\",\"https://arxiv.org/pdf/1602.06023.pdf\", \"https://arxiv.org/pdf/1910.12840.pdf\", \"https://arxiv.org/pdf/2010.02443.pdf\", \"https://arxiv.org/ftp/arxiv/papers/1906/1906.04165.pdf\"])\n",
    "\n",
    "loader = WebBaseLoader([\"https://towardsdatascience.com/the-secret-guide-to-human-like-text-summarization-fcea0bfbe801\",\n",
    "                        \"https://blog.floydhub.com/gentle-introduction-to-text-summarization-in-machine-learning/\", \n",
    "                        \"https://medium.com/analytics-vidhya/text-summarization-using-nlp-3e85ad0c6349\", \n",
    "                        \"https://medium.com/@dilip.voleti/concept-of-text-summarization-3745ffc8d84e\", \n",
    "                        \"https://medium.com/luisfredgs/automatic-text-summarization-with-machine-learning-an-overview-68ded5717a25\"])\n",
    "index = VectorstoreIndexCreator(embedding=HuggingFaceEmbeddings()).from_loaders([loader])\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "233ad56b-fae3-4f5d-bf19-644f24b7ba68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Secret Guide To Human-Like Text Summarization | by Louis Teo | Medium | Towards Data SciencePhoto by NeONBRAND on UnsplashThe Secret Guide To Human-Like Text SummarizationUse Googleâ€™s state-of-the-art T5 model to summarize your contentLouis TeoÂ·FollowPublished inTowards Data ScienceÂ·11 min readÂ·Apr 27, 2021--3ListenShareSummarization has become a very helpful way of tackling the issue of data overburden. In my earlier story, I shared how you can create your personal text summarizer usin\n"
     ]
    }
   ],
   "source": [
    "# This is just making sure we can actually load the articles. This just loads a subset of the first article\n",
    "print(data[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e786d70a-d8ea-4e36-8ff4-020d7ef22fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Define the text splitter with chunk_size and chunk_overlap as parameters\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=50)\n",
    "\n",
    "# Split the documents into smaller chunks\n",
    "all_splits = text_splitter.split_documents(data)\n",
    "\n",
    "# This will give you a list of smaller text segments from each article\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "449a0412-dabc-4f3b-b98d-91a8b06993fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# Create simple IDs for the chunks\n",
    "ids = [str(i) for i in range(1, len(all_splits) + 1)]\n",
    "\n",
    "# Generate and store embeddings\n",
    "vectorstore = Chroma.from_documents(documents=all_splits, embedding=HuggingFaceEmbeddings(), ids=ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "415b1c2f-abc1-401a-9230-5e238707e4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of components for 90% variance: 132\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Extract the embeddings from the vectorstore\n",
    "embeddings = vectorstore._collection.get(ids=ids, include=['embeddings'])['embeddings']\n",
    "\n",
    "# Standardize the embeddings\n",
    "scaler = StandardScaler()\n",
    "embeddings_scaled = scaler.fit_transform(embeddings)\n",
    "\n",
    "# Apply PCA with all components to find the explained variance\n",
    "pca_all = PCA()\n",
    "embeddings_pca_all = pca_all.fit_transform(embeddings_scaled)\n",
    "cumulative_explained_variance = pca_all.explained_variance_ratio_.cumsum()\n",
    "\n",
    "# Find the number of components for 90% variance\n",
    "num_components_90_variance = (cumulative_explained_variance >= 0.9).argmax() + 1\n",
    "\n",
    "print(\"Number of components for 90% variance:\", num_components_90_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "608acae9-aaab-4524-975f-e6ee1d955e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 3 PCA components and 3 clusters:\n",
      "Cluster Centers: [[-7.88160149 -3.01620462 -1.65031871]\n",
      " [ 9.11060711 -2.69746491  1.87607479]\n",
      " [-0.1402855  11.98302237  0.03210155]]\n",
      "Cluster Labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 2 0 2 2 2 0 1 0 1 1 1 1 1 1 2 0 2 1 0\n",
      " 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1\n",
      " 1 1 1 1 1 1 1 0 0 1 1 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0 0\n",
      " 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 1 1 0 2 1 1 2 2 1 2 2 2 2 2 2 2 2 1 1 2 2 1\n",
      " 2 2 2 2 2 0 0 0 0 0 2 2 2 2 2 0 1 2 1 2 2 2 2 2 1 1 1 2 2 0 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 0 0 0 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 0 0 1 0 0 0 1 0 0 0 0 0 1 1\n",
      " 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2\n",
      " 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1\n",
      " 1 0 0 0 1 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 0 0 1 0 0 1 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 1 1 1 1 1 0 1 1 1 0 1 1 1\n",
      " 1 1 1 1 0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1]\n",
      "For 3 PCA components and 5 clusters:\n",
      "Cluster Centers: [[ 17.4218893   -4.66320398 -10.16646902]\n",
      " [ -8.26136953  -2.98228116  -2.30707899]\n",
      " [  2.20170753  -2.73770969   9.25929702]\n",
      " [ -0.54401279  12.64219876  -0.19423235]\n",
      " [  9.06643261  -0.63404428   1.74783404]]\n",
      "Cluster Labels: [1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 4 2 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 4 0 0 0 0 0 0 0 0 4 0 2 1 2 2 3 3 3 1 2 1 4 0 0 0 4 2 2 1 3 2 1\n",
      " 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 4 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 4\n",
      " 2 2 4 4 4 4 4 1 1 2 4 1 1 2 2 2 1 1 1 1 4 1 1 1 1 1 1 1 2 4 1 1 4 4 1 1 1\n",
      " 1 1 1 1 3 1 1 2 1 1 1 1 1 1 1 4 4 1 3 4 4 3 3 4 2 3 3 3 3 3 3 3 4 4 3 3 4\n",
      " 3 4 4 4 3 1 1 1 1 1 3 3 3 3 3 1 4 3 4 4 3 3 3 4 4 4 4 3 3 2 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 1 3 3 3 3 3 3 3 3 1 1 1 3 4 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 2 1 1 4 1 1 1 2 1 1 2 1 1 2 2\n",
      " 1 4 4 4 4 2 2 2 2 2 2 2 4 4 2 2 4 4 4 4 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3\n",
      " 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 1 4 4 4 4 4 2 4 1 1 4\n",
      " 2 2 1 1 2 2 2 1 1 1 4 4 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 1\n",
      " 1 1 1 1 1 1 1 1 1 4 1 1 1 1 1 1 2 2 4 2 4 4 1 1 1 2 2 1 1 2 1 2 2 2 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 4 4 4 4 4 4 2 4 4 4 4 4\n",
      " 1 1 1 2 2 1 1 1 1 1 1 1 1 2 1 2 1 1 1 2 2 1 2 1 2 2 2 2 2 1 2 2 2 2 2 2 2\n",
      " 2 2 2 2 1 1 2 1 2 1 2 2 1 2 2 2 1 2 2 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 2 2 2 2 2 4 4 2 4 2 2 2 2 1 1 2 2 2]\n",
      "For 3 PCA components and 10 clusters:\n",
      "Cluster Centers: [[  0.2811105   16.8687228    0.03457856]\n",
      " [ -0.86479234  -0.6141513    6.49494902]\n",
      " [ -9.36560079  -2.84653757  -5.52386111]\n",
      " [ 17.51317412  -4.71226303 -10.41379021]\n",
      " [ 11.32481767   0.07787727   0.39062316]\n",
      " [  7.69058532  -3.84428939   4.86178092]\n",
      " [  2.53227262   6.20031516   1.64040756]\n",
      " [  3.28946089  -4.1576303   11.86959082]\n",
      " [ -5.19061858   6.09322033  -3.34126248]\n",
      " [ -7.63817119  -4.64372494   1.03616646]]\n",
      "Cluster Labels: [2 9 9 2 9 9 9 2 2 9 2 9 8 1 7 5 7 4 3 3 3 3 3 3 3 4 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 4 3 3 3 3 3 3 3 3 4 3 1 1 6 1 6 6 6 1 1 9 4 3 3 3 4 1 6 8 6 7 9\n",
      " 8 8 3 3 3 3 3 3 3 3 3 3 4 3 3 3 3 9 3 3 4 8 9 2 2 9 2 8 8 8 2 9 9 7 9 7 5\n",
      " 5 5 5 5 5 5 5 9 9 7 4 2 9 1 1 7 9 9 2 2 5 2 2 2 2 9 9 2 7 4 2 2 6 6 2 2 2\n",
      " 2 2 2 2 8 8 9 1 9 9 9 9 9 2 2 4 4 2 8 6 4 6 6 6 6 6 6 0 0 0 0 0 6 4 0 0 4\n",
      " 0 6 6 6 8 8 8 9 2 8 8 0 0 8 8 8 4 6 4 6 6 6 8 6 6 6 6 6 6 1 6 6 0 0 0 6 0\n",
      " 0 0 0 0 8 6 6 0 0 0 0 0 0 0 0 0 6 8 8 6 2 0 0 0 8 8 8 8 8 8 9 9 6 6 6 6 8\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 8 8 8 0 0 0 8 8 4 5 8 2 5 2 2 9 7 9 2 1 9 9 7 7\n",
      " 2 5 5 5 4 5 5 5 7 7 5 5 4 4 7 7 5 5 5 5 2 2 2 2 2 2 2 2 2 2 9 2 2 2 2 2 8\n",
      " 6 6 0 0 0 0 0 0 0 8 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 9 5 4 4 6 4 5 5 9 9 5\n",
      " 1 1 8 9 7 1 1 2 2 2 5 5 2 2 9 2 2 2 9 2 2 2 2 2 2 2 2 2 1 8 2 2 9 9 9 7 9\n",
      " 9 9 9 9 2 2 2 2 9 5 9 2 2 2 2 2 7 1 5 5 5 5 9 9 9 1 7 2 9 1 1 9 7 7 2 9 9\n",
      " 2 2 9 2 1 2 2 9 9 2 2 9 2 2 2 9 2 2 2 2 1 8 8 2 8 5 5 4 4 4 5 5 5 5 5 5 4\n",
      " 9 9 9 1 7 9 9 9 9 2 9 9 9 7 9 1 9 9 9 7 7 9 1 9 7 7 7 1 7 9 7 7 7 1 1 7 7\n",
      " 7 7 1 1 9 9 1 9 9 9 1 1 9 1 1 1 1 7 7 9 7 9 9 9 7 9 9 2 2 2 2 9 9 9 9 2 2\n",
      " 9 9 9 9 2 2 9 7 7 5 7 1 5 5 1 5 7 7 7 1 9 2 5 7 1]\n",
      "For 7 PCA components and 3 clusters:\n",
      "Cluster Centers: [[-7.97818509 -2.47660662 -2.17023504 -0.13787123  0.10507764  0.49733607\n",
      "  -0.24593388]\n",
      " [16.57469977 -4.4920783  -9.60836806 -4.64190318 -2.94774296 -2.39406631\n",
      "  -0.69690752]\n",
      " [ 3.88273709  3.32691826  4.16404172  1.15206608  0.54974698  0.05755181\n",
      "   0.3855926 ]]\n",
      "Cluster Labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 0 2 0 2 2 2 0 2 0 1 1 1 1 1 2 2 0 2 2 0\n",
      " 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 2 0 2 2\n",
      " 2 2 2 2 2 2 2 0 0 2 2 0 0 2 2 2 0 0 0 0 2 0 0 0 0 0 0 0 2 2 0 0 2 2 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 0 0 0 0 0 0 2 2 2 2 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 0 0 2 0 0 0 0 0 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 2 2 2 0 0 2 2 0 0 2 0 0 0 2 0 0 2 0 0 2 2\n",
      " 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 0 0 2\n",
      " 2 2 0 0 2 2 2 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0\n",
      " 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 2 2 2 2 2 0 0 0 2 2 0 0 2 0 0 2 2 0 0 0\n",
      " 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 0 0 0 2 2 0 0 0 0 0 0 0 0 2 0 2 0 0 0 2 2 0 0 0 2 2 2 2 2 0 2 2 2 2 2 2 2\n",
      " 2 2 2 2 0 0 0 0 0 0 2 0 0 2 2 2 0 2 2 0 2 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 2 2 2]\n",
      "For 7 PCA components and 5 clusters:\n",
      "Cluster Centers: [[-0.56920798 13.66389542 -0.12436035 -0.49941189 -1.7087751  -0.67067345\n",
      "  -0.34929582]\n",
      " [-0.80683761 -2.49628329  8.48457185 -5.6150128  -0.88848386 -0.2401038\n",
      "   0.42060017]\n",
      " [ 7.73606833 -0.98159902  3.36100719  5.46040716  3.02220941  1.43479861\n",
      "   0.11476497]\n",
      " [16.80719166 -4.52048802 -9.7919204  -4.82647656 -3.01561918 -2.53137066\n",
      "  -0.73992173]\n",
      " [-8.28954872 -2.71245273 -3.02646316  0.81200527  0.14775233  0.22315845\n",
      "   0.08669305]]\n",
      "Cluster Labels: [4 4 4 4 4 4 4 4 4 4 4 4 4 1 1 2 1 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 2 3 3 3 3 3 3 3 3 3 3 1 1 1 1 1 1 1 1 1 1 3 3 3 3 2 1 1 4 1 1 4\n",
      " 4 4 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 1 4 2 2\n",
      " 2 2 2 2 2 2 2 4 4 2 2 4 4 2 2 1 4 4 4 4 2 4 4 4 4 4 4 4 2 2 4 4 2 2 4 4 4\n",
      " 4 4 4 4 0 4 4 1 4 4 4 1 4 4 4 2 2 4 4 2 2 0 0 2 1 0 0 0 0 0 0 0 2 2 0 0 2\n",
      " 0 2 2 2 0 4 4 4 4 4 0 0 0 0 4 4 2 2 2 2 2 0 0 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 4 0 0 0 0 4 4 4 0 2 2 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 2 2 4 4 2 4 4 4 1 4 4 1 4 4 1 1\n",
      " 4 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 2 2 2 2 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 0\n",
      " 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 4 2 2 2 2 2 2 2 4 4 2\n",
      " 1 1 4 4 1 1 1 4 4 4 2 2 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 1 4 4 4 4 4 4 1 1\n",
      " 1 4 1 4 4 4 4 4 4 2 4 4 4 4 4 4 1 2 2 2 2 2 4 4 4 1 1 4 4 2 4 1 1 1 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 1 4 4 4 4 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 4 4 4 1 1 1 4 4 4 4 4 1 1 1 4 1 1 1 4 1 1 4 1 1 1 1 1 1 1 4 1 1 1 1 2 1 1\n",
      " 1 1 1 1 1 1 1 4 1 1 1 1 4 1 1 1 4 1 1 4 1 4 1 4 1 1 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 1 1 4 4 4 4 2 2 2 2 2 2 2 2 2 2 2 1 1 4 4 2 1 1]\n",
      "For 7 PCA components and 10 clusters:\n",
      "Cluster Centers: [[-4.85623111  6.25639518 -2.88048779 -2.52687295  5.19974855  1.5279381\n",
      "  -4.08909283]\n",
      " [-8.59406548 -2.61366522 -3.96708301  2.34125079 -0.62593879 -0.0751999\n",
      "   1.06713449]\n",
      " [16.57469977 -4.4920783  -9.60836806 -4.64190318 -2.94774296 -2.39406631\n",
      "  -0.69690752]\n",
      " [ 7.27887243 -3.43566261  5.09726187  7.60037481  0.56576801 -1.00886022\n",
      "  -1.81192576]\n",
      " [ 1.40237967 -2.74607249 10.6041595  -5.84101109 -1.29021597 -0.48630416\n",
      "   0.84438044]\n",
      " [11.28854001  3.02549142  1.12442056  2.23577114  4.08683006 13.30452945\n",
      "   2.59408691]\n",
      " [ 0.79022744  6.63594965  2.96105888  0.82711095 -3.4967529  -2.25413955\n",
      "   6.90783878]\n",
      " [ 3.06891487  6.59208479  0.15324821 -1.48019739 13.42203565 -5.75582987\n",
      "   2.89719283]\n",
      " [-7.88881979 -5.2721794   2.00780284 -4.71731774  0.05540286  1.39048794\n",
      "  -2.30107244]\n",
      " [-0.34899406 17.24518345 -0.30384396 -0.1159583  -4.42793033  0.35058553\n",
      "  -2.81459496]]\n",
      "Cluster Labels: [1 1 1 1 1 8 1 1 1 8 8 8 0 4 4 3 4 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 4 0 4 8 7 0 0 8 4 8 2 2 2 2 2 4 6 0 0 4 8\n",
      " 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 8 2 2 2 0 1 1 1 8 1 0 0 0 1 8 8 4 8 3 3\n",
      " 3 3 3 3 3 3 3 1 8 3 3 1 1 3 3 4 1 1 1 1 3 1 1 1 1 1 1 1 3 3 1 1 6 7 1 1 1\n",
      " 1 1 1 1 0 1 8 4 1 1 8 8 8 1 1 5 5 1 6 6 5 6 6 6 6 6 6 9 9 9 9 9 6 5 9 6 5\n",
      " 9 5 5 5 1 1 1 1 1 0 9 9 9 0 0 0 3 7 7 7 7 7 7 7 7 7 7 7 7 6 6 6 6 6 6 6 6\n",
      " 6 9 9 5 7 7 7 9 9 9 9 9 9 9 9 9 6 6 6 6 1 9 9 9 0 0 0 0 0 0 1 0 7 7 7 7 7\n",
      " 6 9 9 9 9 9 9 9 9 9 9 9 9 0 0 0 9 9 9 0 0 3 3 1 1 3 1 1 8 4 8 1 4 8 8 4 4\n",
      " 1 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 3 3 3 3 1 1 1 1 1 1 1 1 1 1 8 8 1 1 1 1 0\n",
      " 7 7 6 9 9 9 9 9 9 0 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 1 3 3 3 7 7 3 3 1 1 3\n",
      " 4 3 1 1 4 6 6 1 1 1 3 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 8 4 1 1 1 1 1 8 4 8\n",
      " 8 8 8 1 1 1 1 1 1 3 1 1 1 1 1 1 3 6 3 3 3 3 1 8 1 6 4 1 1 3 1 8 4 4 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 8 1 1 1 1 1 1 1 1 8 1 1 1 0 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 8 8 8 4 4 8 8 1 1 1 8 6 8 4 8 4 8 8 8 4 4 8 4 8 4 4 4 4 4 8 4 4 4 4 3 4 4\n",
      " 4 4 4 4 8 8 4 8 8 8 4 4 1 4 4 4 6 4 4 8 4 8 8 8 4 8 1 1 1 1 1 1 1 8 8 1 1\n",
      " 8 8 8 8 1 1 1 3 3 3 3 3 3 3 3 3 3 3 4 4 8 1 3 4 6]\n",
      "For 19 PCA components and 3 clusters:\n",
      "Cluster Centers: [[ 1.65746998e+01 -4.49207867e+00 -9.60837134e+00 -4.64193336e+00\n",
      "  -2.94794471e+00 -2.39385018e+00 -6.96964930e-01  3.72148424e-01\n",
      "  -5.24737193e-02  4.55407096e-01  3.68070497e-01  2.07415581e-01\n",
      "  -6.77580507e-02 -3.55129611e-01  6.55767512e-01  1.51553114e-01\n",
      "  -4.58302869e-01  1.31473670e-01  3.28458134e-01]\n",
      " [-7.97818509e+00 -2.47660654e+00 -2.17023473e+00 -1.37867825e-01\n",
      "   1.05069351e-01  4.97355439e-01 -2.45942604e-01 -2.30466994e-01\n",
      "  -2.02647336e-01  3.00372627e-02  1.81155538e-01  3.67994703e-02\n",
      "  -9.30251307e-02  4.59056148e-02  4.28025477e-03 -9.69860057e-02\n",
      "   1.05278162e-02  1.00568678e-02  4.19385620e-02]\n",
      " [ 3.88273709e+00  3.32691827e+00  4.16404214e+00  1.15206951e+00\n",
      "   5.49799224e-01  5.74859493e-02  3.85613469e-01  1.35639524e-01\n",
      "   2.02857185e-01 -1.28613605e-01 -2.52046681e-01 -8.04021839e-02\n",
      "   1.02735385e-01  3.48452482e-02 -1.48407417e-01  5.81933795e-02\n",
      "   9.09564618e-02 -3.84378137e-02 -1.11901067e-01]]\n",
      "Cluster Labels: [1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 2 1 2 2 2 1 2 1 0 0 0 0 0 2 2 1 2 2 1\n",
      " 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 2\n",
      " 2 2 2 2 2 2 2 1 1 2 2 1 1 2 2 2 1 1 1 1 2 1 1 1 1 1 1 1 2 2 1 1 2 2 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 1 1 1 1 1 1 2 2 2 2 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 1 1 2 1 1 1 1 1 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 2 2 2 1 1 2 2 1 1 2 1 1 1 2 1 1 2 1 1 2 2\n",
      " 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 1 2\n",
      " 2 2 1 1 2 2 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 1\n",
      " 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 2 2 2 2 2 1 1 1 2 2 1 1 2 1 1 2 2 1 1 1\n",
      " 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 1 1 1 2 2 1 1 1 1 1 1 1 1 2 1 2 1 1 1 2 2 1 1 1 2 2 2 2 2 1 2 2 2 2 2 2 2\n",
      " 2 2 2 2 1 1 1 1 1 1 2 1 1 2 2 2 1 2 2 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 2 2 2]\n",
      "For 19 PCA components and 5 clusters:\n",
      "Cluster Centers: [[-8.28954872e+00 -2.71245270e+00 -3.02646308e+00  8.12006278e-01\n",
      "   1.47735558e-01  2.23156173e-01  8.67622253e-02 -6.29617718e-01\n",
      "  -1.30543813e-01 -2.19693897e-01  3.69345295e-02  1.87759548e-01\n",
      "  -6.03175111e-02  6.79984601e-02 -5.53245887e-03 -7.61488330e-02\n",
      "  -2.03476271e-02 -4.02078819e-02  7.44105530e-02]\n",
      " [-8.82316315e-01 -2.59806417e+00  8.54096486e+00 -5.76822946e+00\n",
      "  -8.18863425e-01 -2.26960202e-01  2.59421577e-01 -2.05279411e-01\n",
      "  -4.07716758e-01  7.25381922e-01 -3.83343971e-02  5.58072539e-02\n",
      "   9.45457034e-02  3.54691282e-01  1.14616788e-01  5.01216888e-01\n",
      "  -6.82883591e-03 -5.38518801e-01 -1.77172387e-01]\n",
      " [ 1.65746998e+01 -4.49207867e+00 -9.60837134e+00 -4.64193336e+00\n",
      "  -2.94794471e+00 -2.39385018e+00 -6.96964930e-01  3.72148424e-01\n",
      "  -5.24737193e-02  4.55407096e-01  3.68070497e-01  2.07415581e-01\n",
      "  -6.77580507e-02 -3.55129611e-01  6.55767512e-01  1.51553114e-01\n",
      "  -4.58302869e-01  1.31473670e-01  3.28458134e-01]\n",
      " [ 7.57334634e+00 -8.35379311e-01  3.52482340e+00  5.43954302e+00\n",
      "   2.92494705e+00  1.39089248e+00  3.41016649e-01  2.66243303e-01\n",
      "   2.85962352e-01 -6.23579890e-01 -2.10128250e-01 -1.61863685e-01\n",
      "   5.02459285e-01 -2.37124883e-01 -7.05753314e-01 -2.91306343e-01\n",
      "  -5.70442811e-02 -3.07356862e-02  2.37794953e-02]\n",
      " [-5.97444139e-01  1.37582162e+01 -1.64399108e-01 -5.17434780e-01\n",
      "  -1.69478420e+00 -6.86423376e-01 -5.10034455e-01  1.14771543e+00\n",
      "   3.84664109e-01  3.57147477e-01  1.57600616e-03 -4.33916042e-01\n",
      "  -6.27285674e-01  3.35551819e-02  4.60511849e-01 -3.09582015e-02\n",
      "   4.50581306e-01  6.30484658e-01 -2.52265681e-01]]\n",
      "Cluster Labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 3 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 1 1 0 1 1 0\n",
      " 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 0 0 0 0 0 0 0 0 0 0 0 0 1 0 3 3\n",
      " 3 3 3 3 3 3 3 0 0 3 3 0 0 3 3 1 0 0 0 0 3 0 0 0 0 0 0 0 3 3 0 0 3 3 0 0 0\n",
      " 0 0 0 0 4 0 0 1 0 0 0 1 0 0 0 3 3 0 0 3 3 3 4 3 3 4 4 4 4 4 4 4 3 3 4 4 3\n",
      " 4 3 3 3 4 0 0 0 0 0 4 4 4 4 0 0 3 3 3 3 3 4 4 3 3 3 3 3 3 3 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 0 4 4 4 0 4 4 4 4 0 0 0 4 3 3 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 0 3 3 0 0 3 0 0 0 1 0 0 1 0 0 1 1\n",
      " 0 3 3 3 3 3 3 3 3 3 3 3 3 3 1 1 3 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4\n",
      " 4 4 4 4 4 4 4 4 4 4 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 0 3 3 3 3 3 3 3 0 0 3\n",
      " 1 1 0 0 1 1 1 0 0 0 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1\n",
      " 1 0 1 0 0 0 0 0 0 3 0 0 0 0 0 0 1 3 3 3 3 3 0 0 0 1 1 0 0 3 0 1 1 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 0 0 0 1 1 1 0 0 0 0 0 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 3 1 1\n",
      " 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 1 0 0 0 0 3 3 3 3 3 3 3 3 3 3 3 1 1 0 0 3 1 3]\n",
      "For 19 PCA components and 10 clusters:\n",
      "Cluster Centers: [[ 1.99954162 14.10810184  1.077136    0.65646469 -2.17538898 -3.25171604\n",
      "   3.82664296 -3.05580362 -1.38375005 -1.17316282 -0.3754379  -1.5459611\n",
      "  -2.49767062  1.93459475  3.70815198  0.26416314 -0.04158863  0.07726376\n",
      "   0.26419861]\n",
      " [16.57469979 -4.49207867 -9.60837134 -4.64193336 -2.94794471 -2.39385018\n",
      "  -0.69696493  0.37214842 -0.05247372  0.4554071   0.3680705   0.20741558\n",
      "  -0.06775805 -0.35512961  0.65576751  0.15155311 -0.45830287  0.13147367\n",
      "   0.32845813]\n",
      " [ 0.80882305  6.30726234 -0.89847521 -3.00758056 12.72334888 -2.65902719\n",
      "   0.88147007  3.13602331 -1.59099367  0.15021741  1.10082845 -0.27801429\n",
      "  -0.69578155  0.19625589 -0.87467381  1.00806058 -1.06261312 -0.0493605\n",
      "  -0.53674013]\n",
      " [ 5.2695433   5.72354521  1.54245331  0.71344419 -0.82421266  5.31926439\n",
      "   7.46419113  3.09430705  2.99097546 -7.85466911  6.86377846  0.46733982\n",
      "   8.75545957 -0.43217551 -0.37968202  0.30890407 -0.4176185   0.6639146\n",
      "   2.81287949]\n",
      " [-7.56903973 -4.20724986  1.80447402 -4.41853188  0.52009049  1.03485695\n",
      "  -2.61800398 -1.10358135 -0.5738353   0.57045997  1.15943045 -0.84266887\n",
      "   0.22063799  0.90592749  0.80444998 -0.53978057 -0.58212094 -0.52110102\n",
      "   0.44961056]\n",
      " [ 1.10864286 -2.83384434 10.24262193 -5.32870618 -1.81182471 -0.74919676\n",
      "   1.24760503  0.37877308  0.21442548 -0.41617414 -1.16906883  0.52404693\n",
      "  -0.24288686 -0.26330937 -0.24193878  0.46650886  0.7928204  -0.7328611\n",
      "  -0.80726964]\n",
      " [12.70099105  1.61029564  1.49018181  2.9066323   5.69406169 16.04067638\n",
      "   1.52648266 -6.34511416  9.60793737  3.20504351 -3.68691683  1.49123065\n",
      "  -4.96197071  1.12603351 -0.47082425 -1.20574444 -2.55742387 -0.82306158\n",
      "   2.83600413]\n",
      " [-8.14829386 -2.29865911 -3.837953    2.31292375 -0.47363751 -0.14240633\n",
      "   1.35997695 -0.58733242 -0.05083106 -0.16656947 -0.19340499  0.71801405\n",
      "  -0.28498445 -0.07166119 -0.40656976  0.08396216  0.0634697   0.04291299\n",
      "   0.03836817]\n",
      " [-2.54940745 15.27805911 -1.06420823 -0.53523034 -4.2060384   1.67541735\n",
      "  -5.41921894  3.19699711  0.97051945  1.38973281 -1.35439648  0.22497131\n",
      "   0.59858348 -1.62793584 -1.90352808 -0.42773833  0.82338412  0.56417334\n",
      "  -0.97068979]\n",
      " [ 7.50968686 -3.09950582  5.18802249  7.53099262  0.67761322 -0.93166135\n",
      "  -1.73655563  0.66043227 -1.22469843  0.34499791 -0.22651476 -1.02735054\n",
      "   0.97196873 -0.41879835 -0.19804652 -0.28431583  0.77403328  0.62776841\n",
      "  -0.59447262]]\n",
      "Cluster Labels: [7 7 7 7 7 4 7 7 7 4 4 4 4 5 5 9 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 4 4 2 4 2 2 2 4 5 4 1 1 1 1 1 4 4 2 2 5 4\n",
      " 4 7 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 4 1 1 1 7 7 7 7 4 7 4 7 7 7 4 4 5 4 9 9\n",
      " 9 9 9 9 9 9 9 7 4 9 9 7 7 7 9 5 7 7 7 7 9 7 7 7 7 7 7 7 9 9 7 7 7 2 7 7 7\n",
      " 7 7 7 7 8 7 4 5 7 7 4 4 4 7 7 3 3 7 3 3 3 3 0 7 3 3 3 3 8 0 0 0 3 3 8 0 9\n",
      " 8 3 3 3 8 7 7 7 7 4 0 0 8 8 2 7 9 2 2 2 2 2 2 2 2 2 2 2 2 7 0 0 0 0 0 0 0\n",
      " 0 0 0 0 2 0 2 8 8 8 8 8 8 8 8 8 8 0 7 8 7 8 8 8 2 8 2 8 2 2 4 7 2 2 2 2 2\n",
      " 0 0 0 0 8 8 8 8 8 8 8 8 8 8 8 2 0 8 8 8 2 9 9 7 7 9 7 7 4 5 4 4 5 4 4 5 5\n",
      " 7 9 9 9 9 9 9 9 9 9 9 9 9 9 5 5 9 9 9 9 7 7 7 7 7 7 7 7 7 7 4 4 7 7 7 7 0\n",
      " 0 2 0 0 0 0 0 8 8 8 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 7 9 9 9 9 9 9 9 7 4 9\n",
      " 5 4 7 7 5 5 5 7 7 7 7 9 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 5 7 7 7 7 7 4 5 4\n",
      " 4 4 4 7 7 7 7 7 7 9 7 7 7 7 7 7 9 9 9 9 9 9 7 4 7 5 5 7 7 9 7 4 5 5 7 7 7\n",
      " 7 7 7 7 7 7 7 7 7 7 7 4 7 7 7 7 7 7 7 7 5 7 7 7 7 9 9 9 9 9 9 9 9 9 9 9 9\n",
      " 4 4 4 5 5 4 4 7 7 7 4 5 4 5 4 5 4 5 4 5 5 4 4 4 5 5 5 5 5 4 5 5 5 5 9 5 5\n",
      " 5 5 5 5 4 4 5 4 5 4 5 5 7 5 5 5 7 5 5 4 5 4 4 4 5 4 4 7 7 7 7 7 7 4 4 7 7\n",
      " 4 4 4 4 7 7 7 9 9 9 9 9 9 9 9 9 9 9 5 5 4 7 9 5 5]\n",
      "For 132 PCA components and 3 clusters:\n",
      "Cluster Centers: [[-7.90782168e+00 -2.94348843e+00 -1.66664912e+00 -1.34260276e-01\n",
      "  -2.23121756e-01  2.11498926e-01  6.47620265e-02 -5.75481331e-01\n",
      "  -8.48502065e-02 -2.06193961e-02  1.98000748e-02  1.57613255e-01\n",
      "  -4.33302121e-02  8.17646409e-02 -3.26408624e-02 -2.32034725e-01\n",
      "  -8.95393693e-02 -8.74555539e-02  9.90214576e-02 -1.17370390e-01\n",
      "   1.16079738e-01  2.02770410e-02  7.88672667e-02  1.20934065e-01\n",
      "  -1.55195557e-01 -1.71647647e-01 -8.97749519e-02 -9.84443737e-04\n",
      "  -1.76600662e-02 -6.22190409e-04  8.39746005e-02 -3.09281833e-02\n",
      "   4.79152529e-02  5.90062916e-02  5.98006081e-02 -8.61612410e-02\n",
      "   3.87614437e-03 -4.17831714e-03 -9.43851351e-03 -2.97137666e-02\n",
      "   5.27797035e-02  2.00106661e-02 -2.86089603e-02  1.14108382e-01\n",
      "   9.14980007e-02  2.15462248e-03 -7.60343046e-02 -1.12004640e-02\n",
      "  -2.13121529e-02  1.07936758e-02 -1.03619586e-01  1.69961067e-02\n",
      "  -3.38619725e-02  8.44235546e-04  7.00317352e-03  6.32389629e-02\n",
      "  -4.03262397e-02  5.90591075e-02 -9.03602175e-03  6.35866036e-02\n",
      "  -1.01319827e-01 -4.89251006e-02 -7.52806282e-02  1.90408412e-02\n",
      "   5.31103770e-02  4.86472423e-02  4.41266476e-02  5.03336319e-02\n",
      "  -5.92035405e-02  4.29785311e-02 -8.94895991e-02 -1.57780713e-02\n",
      "  -4.72612173e-02  8.44140269e-03  2.06876314e-02 -1.79946507e-02\n",
      "   4.70022415e-02 -3.47956145e-02  3.82384572e-02  6.33460045e-02\n",
      "   1.67137421e-02 -1.08686529e-02 -7.68548178e-03 -1.09113311e-02\n",
      "  -7.18502922e-03  3.28737460e-03 -9.05970849e-03  4.72134949e-02\n",
      "   8.46279909e-04 -1.88326561e-03 -3.74184744e-02 -2.71203732e-03\n",
      "   4.84461178e-03 -2.39107347e-02  4.06745348e-03  4.95288574e-02\n",
      "  -1.13672871e-02  2.32561443e-02 -4.29729906e-02 -2.21920178e-02\n",
      "   3.18688605e-02 -6.98419878e-03 -2.07610879e-02 -1.39853091e-02\n",
      "  -1.22936873e-02 -1.98942850e-02  1.95300607e-03 -2.54822243e-02\n",
      "  -3.83357390e-02  1.40211492e-02  3.53825151e-02 -4.29640474e-02\n",
      "  -9.94976914e-04  5.69279393e-03  3.00106709e-02  1.77534737e-03\n",
      "  -2.13329717e-02 -2.05547416e-02  5.45552560e-03 -2.04002057e-02\n",
      "   9.71434489e-03  7.58734624e-03  7.41431153e-03 -1.27717856e-02\n",
      "   2.65803555e-03  2.39563454e-02 -1.15365520e-04  2.49475248e-02\n",
      "   2.61723257e-03 -3.51290443e-02  3.74718119e-03 -4.19918986e-04]\n",
      " [ 9.10959959e+00 -2.81984352e+00  1.90696471e+00  6.36003957e-01\n",
      "  -4.78348614e-01  2.43612211e-01 -1.95212214e-01  4.12452494e-03\n",
      "   2.46409742e-01  1.42913761e-01 -2.47046675e-01 -4.67128024e-04\n",
      "   2.74238609e-02 -1.83967335e-01 -4.17021960e-02  1.64101234e-01\n",
      "   1.66354757e-01 -8.27656913e-02 -1.03009432e-01  3.84023412e-02\n",
      "  -1.70329944e-01  8.52852743e-02  2.60362774e-02 -1.38778737e-01\n",
      "   1.30613468e-01  9.68789072e-02  1.27826611e-01 -4.59416377e-03\n",
      "  -3.35512310e-02 -1.78475816e-01  4.51494539e-03  8.79178026e-02\n",
      "  -7.28199040e-02 -8.69129664e-03 -6.41706188e-03  1.18520842e-01\n",
      "   1.51109131e-01  1.44814093e-01 -3.70230223e-02 -2.98912793e-02\n",
      "   3.48526860e-02  4.43543266e-02 -9.40583606e-02 -8.44992906e-02\n",
      "  -1.04461707e-01  4.99596941e-02  2.10574540e-02 -2.52097390e-02\n",
      "   9.32995039e-03  3.97519310e-02  3.42324261e-02  1.03275648e-01\n",
      "   1.33049978e-02  5.35745955e-02 -1.85684147e-02 -4.90614935e-02\n",
      "  -3.91834937e-02 -6.55023806e-02  6.94753864e-02 -1.01760177e-01\n",
      "   1.16753770e-01  6.61250965e-02  3.47925739e-02 -1.14882502e-02\n",
      "  -2.34856201e-03 -2.31553136e-02 -2.35276517e-02 -2.17603243e-02\n",
      "   6.31532898e-03 -9.00501291e-02  7.75142199e-02  2.65132784e-02\n",
      "   7.81206292e-02  3.71127575e-02 -1.61316187e-02  3.16881014e-03\n",
      "  -4.70609227e-02  3.72314668e-02 -1.88724112e-02 -3.76433520e-02\n",
      "   8.63677118e-03  1.31668690e-03  2.32131566e-02 -9.21048563e-03\n",
      "   2.20202367e-02 -5.74167860e-02  5.11766548e-03 -8.37421035e-03\n",
      "  -4.49017341e-02  6.36386264e-03  2.47112147e-02 -5.63352133e-02\n",
      "  -1.74067997e-02 -1.59992059e-02  3.54781285e-02 -4.17097383e-02\n",
      "  -1.42743068e-02 -3.20838288e-02  3.23704874e-03  5.77267678e-03\n",
      "  -6.08949297e-02 -2.12942146e-02  3.16218170e-02 -2.47649060e-02\n",
      "   1.81130248e-02  5.29646835e-02  1.23071895e-03  5.46615694e-04\n",
      "   5.78401640e-02  2.30740574e-02 -6.99556607e-03  3.11169836e-02\n",
      "  -1.01546655e-03  1.08232533e-02 -5.77419783e-02 -5.36610975e-02\n",
      "   4.47564815e-02  2.57176342e-02 -1.08757589e-02 -1.56253937e-02\n",
      "  -6.55167122e-03 -2.18211138e-02 -9.61052067e-03  4.15636215e-03\n",
      "  -2.88668070e-02 -4.71670571e-02 -3.78926767e-02 -1.58734423e-02\n",
      "   1.70270516e-02 -2.57804161e-02 -1.55999317e-02 -2.98817954e-02]\n",
      " [ 2.30695865e-01  1.17989645e+01  7.30834605e-02 -9.03872996e-01\n",
      "   1.39340801e+00 -9.25112770e-01  2.25573311e-01  1.25928983e+00\n",
      "  -2.77900813e-01 -2.24131493e-01  4.22326460e-01 -3.46144689e-01\n",
      "   4.36820451e-02  1.66930282e-01  1.50516040e-01  2.01394305e-01\n",
      "  -1.16595535e-01  3.48648839e-01 -2.37487538e-02  1.85995304e-01\n",
      "   6.56572245e-02 -2.05490099e-01 -2.22749856e-01 -4.53527844e-03\n",
      "   9.53700795e-02  1.95215740e-01 -4.34141083e-02  1.08319350e-02\n",
      "   1.02159573e-01  3.37969037e-01 -1.93406474e-01 -9.77136277e-02\n",
      "   3.18381656e-02 -1.13525881e-01 -1.19563898e-01 -3.38202594e-02\n",
      "  -2.93520838e-01 -2.63914670e-01  9.06054095e-02  1.21796320e-01\n",
      "  -1.81938887e-01 -1.27709276e-01  2.40380672e-01 -9.18759336e-02\n",
      "  -4.44500971e-03 -9.89661795e-02  1.27695244e-01  7.22053540e-02\n",
      "   2.93281669e-02 -9.87357701e-02  1.63583723e-01 -2.32195501e-01\n",
      "   4.94629876e-02 -1.02898607e-01  1.96001107e-02 -4.67084087e-02\n",
      "   1.62687169e-01 -6.49845751e-03 -1.11133041e-01  5.19140399e-02\n",
      "   2.88785890e-03 -1.69885571e-02  1.00131880e-01 -2.02568189e-02\n",
      "  -1.12506700e-01 -6.34391700e-02 -5.27837144e-02 -6.97830866e-02\n",
      "   1.18441166e-01  7.52032144e-02  5.08450184e-02 -1.52636751e-02\n",
      "  -4.32751731e-02 -8.85792538e-02 -1.51254162e-02  3.36435364e-02\n",
      "  -1.47321424e-02  6.39415688e-03 -4.85989856e-02 -6.84783022e-02\n",
      "  -5.30882024e-02  2.14468789e-02 -2.68576556e-02  4.13947238e-02\n",
      "  -2.57097242e-02  1.01048052e-01  1.02955154e-02 -8.81590525e-02\n",
      "   8.28197945e-02 -7.85553332e-03  3.57818061e-02  1.12217476e-01\n",
      "   2.21619683e-02  8.28195060e-02 -7.58660390e-02 -3.03872762e-02\n",
      "   5.19488158e-02  9.30465775e-03  8.85110103e-02  3.79743066e-02\n",
      "   4.46782974e-02  5.55376318e-02 -1.39268209e-02  7.74979594e-02\n",
      "  -7.09284935e-03 -5.60872054e-02 -6.62113244e-03  5.50747011e-02\n",
      "  -2.46786382e-02 -7.43879894e-02 -6.47102156e-02  3.59107407e-02\n",
      "   4.10582906e-03 -3.29464099e-02  4.28232188e-02  9.72940681e-02\n",
      "  -3.74391897e-02 -3.24606321e-03  8.49957230e-03  7.43851868e-02\n",
      "  -9.03237944e-03  2.44483822e-02  1.80061185e-03  2.02815817e-02\n",
      "   4.85894437e-02  3.62094261e-02  7.17182652e-02 -2.49915669e-02\n",
      "  -3.78749252e-02  1.25966488e-01  2.11705512e-02  5.72805762e-02]]\n",
      "Cluster Labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 2 0 2 2 2 0 1 0 1 1 1 1 1 1 2 0 2 1 0\n",
      " 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1\n",
      " 1 1 1 1 1 1 1 0 0 1 1 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 2 1 1 2 2 1 2 2 2 2 2 2 2 2 2 1 2 2 1\n",
      " 2 2 2 2 0 0 0 0 0 0 2 2 2 2 2 0 1 2 1 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 0 0 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 0 0 1 0 0 0 1 0 0 0 0 0 1 1\n",
      " 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2\n",
      " 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1\n",
      " 1 0 0 0 1 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 0 0 1 0 0 1 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 1 1 1 1 1 0 1 1 1 0 1 1 1\n",
      " 1 1 1 1 0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1]\n",
      "For 132 PCA components and 5 clusters:\n",
      "Cluster Centers: [[-8.09805885e+00 -2.75324923e+00 -2.82998644e+00  9.06671345e-01\n",
      "  -8.53149098e-02  1.44911824e-01  2.54725322e-01 -5.74482428e-01\n",
      "  -1.53670497e-01 -2.22770356e-01  8.85420211e-03  3.23186758e-01\n",
      "  -2.22467205e-01  4.09998631e-02 -1.00607610e-01 -1.71356294e-01\n",
      "  -7.03873788e-02 -9.49205638e-02  1.06884873e-01 -8.23698282e-02\n",
      "   4.54319209e-02  1.03382239e-02  1.48431114e-01  5.07135252e-02\n",
      "  -5.73460442e-02 -1.05685375e-01 -1.24186238e-01  9.46815938e-02\n",
      "   1.54365301e-02 -2.41650354e-02  1.52513989e-01 -2.37438514e-02\n",
      "   3.26797146e-02  1.21818597e-01 -3.67248814e-02 -3.55457182e-02\n",
      "  -1.54890396e-02  6.80035622e-02 -2.18151015e-02 -8.90209626e-02\n",
      "  -3.90517602e-02  1.69518348e-02 -6.87109939e-02  7.40327962e-02\n",
      "   3.18143597e-02  5.80536731e-02 -1.00169442e-01 -3.19162840e-02\n",
      "  -4.77608151e-03 -1.02927865e-02 -1.06359851e-01  6.43444646e-02\n",
      "  -2.35464162e-02  3.10271516e-04 -2.71198793e-02  4.66915340e-02\n",
      "  -7.43318774e-02 -7.28952758e-03  1.39871178e-01  1.04502602e-01\n",
      "  -5.51551701e-02  6.51082553e-03  3.66981998e-02  2.70175643e-02\n",
      "   7.74829399e-02  3.19826727e-02 -2.34951361e-03  1.94197473e-02\n",
      "   4.96108557e-02 -9.35322842e-03 -6.59167003e-02 -3.59388602e-02\n",
      "   1.13717582e-02  1.82089886e-02  4.13310877e-03 -2.97336198e-02\n",
      "  -4.56560789e-03 -1.83462849e-02  5.14241107e-02  3.34899982e-02\n",
      "   7.20182274e-02  2.90439507e-02  2.86875289e-02 -4.21044769e-02\n",
      "   2.44643043e-03  5.52303498e-02 -7.62534468e-03 -5.80265775e-03\n",
      "   2.01889975e-02 -2.03101647e-02 -4.01425715e-04  2.32433560e-02\n",
      "   1.09293322e-02 -4.71390097e-02  3.85937719e-02  6.47591130e-03\n",
      "  -1.77324056e-02  2.70238829e-02 -4.67539499e-02 -9.86516666e-03\n",
      "   5.39785127e-03  1.72211647e-02 -5.43155830e-02 -2.52810567e-02\n",
      "  -1.63417427e-02  2.33547089e-02 -1.90863289e-02 -2.05118230e-02\n",
      "  -4.03903342e-02  1.16538836e-03  1.29905484e-02  3.73708376e-02\n",
      "   3.32177627e-02  3.01054903e-03  2.80093191e-02 -6.09348155e-02\n",
      "  -1.11891833e-02 -2.60673223e-02  3.18718448e-02 -1.60057364e-02\n",
      "   1.92209990e-02  4.07344080e-03  4.60494522e-02 -2.04623635e-02\n",
      "  -2.01514257e-02  2.18817893e-02  7.27978144e-03 -2.33511682e-02\n",
      "   1.14710326e-02 -1.27564430e-02 -1.17861196e-02  1.52597654e-02]\n",
      " [-5.38684576e-01 -2.37326700e+00  8.65151595e+00 -5.39414883e+00\n",
      "  -8.62609663e-01 -4.33559592e-01  3.04512672e-01 -3.14701385e-01\n",
      "  -1.91757149e-01  6.62934050e-01  4.52592908e-04  1.14146332e-01\n",
      "   2.49388068e-01  5.18510809e-01 -1.39393003e-03  6.73418173e-01\n",
      "  -1.05191831e-01 -5.68574166e-01 -2.65264704e-01 -2.11246084e-01\n",
      "  -9.38440007e-02  4.49496942e-01 -1.36733568e-01 -1.22718991e-01\n",
      "  -1.16578304e-01  1.15406983e-01 -8.12444262e-02 -6.21774251e-03\n",
      "  -1.89231081e-02 -1.20856706e-01 -1.89389609e-01  5.52348629e-01\n",
      "  -5.03933643e-01 -8.57075444e-02  3.76662407e-01  4.14043021e-01\n",
      "   1.96699580e-01  1.35579844e-01 -2.55707025e-01  2.21001185e-01\n",
      "   1.89190053e-01  1.63758191e-01 -5.20879964e-03 -2.23800621e-01\n",
      "  -3.44135351e-01  1.79153249e-01 -3.98240207e-02 -1.94868612e-01\n",
      "   4.35272839e-02 -2.42258389e-03  1.01566314e-01  9.46659617e-02\n",
      "   7.70887481e-02  2.53556221e-01  5.97111554e-02 -3.70264946e-03\n",
      "   3.31142679e-03 -2.32675196e-02 -7.65768627e-02 -1.52349000e-01\n",
      "  -1.70504567e-01  8.95765539e-04 -1.29878429e-01 -1.82533546e-01\n",
      "  -1.44142758e-02  7.63173942e-02 -4.64607203e-02  7.41977332e-02\n",
      "   7.91728487e-03  2.04530220e-01 -1.00532498e-02  7.03102286e-02\n",
      "   1.06112806e-01  6.73396558e-02 -5.43997296e-02  2.36963855e-01\n",
      "  -5.66494801e-02 -1.03715447e-01 -1.66278953e-01 -4.14513540e-02\n",
      "  -5.51827845e-02  8.08141623e-02  2.61631356e-02  1.36117052e-02\n",
      "  -5.28266221e-02 -1.62381992e-01 -1.81345824e-02  1.16293408e-01\n",
      "  -6.60209545e-02 -7.88413497e-03 -4.56291162e-02 -1.10275921e-01\n",
      "   4.73617491e-02  9.82433638e-02 -5.10464119e-02 -5.65936753e-02\n",
      "   4.77463394e-04 -1.26434345e-01  1.49596763e-02 -8.37659286e-02\n",
      "  -1.01710063e-01 -6.26868725e-02  1.17840066e-01 -6.28177251e-02\n",
      "  -4.42814266e-02 -5.05266208e-02 -3.07199988e-02 -1.11892866e-02\n",
      "   1.80041482e-01  3.20436676e-02 -8.44048036e-02 -1.01685493e-01\n",
      "  -8.15527479e-02 -6.70797383e-02  3.63991512e-03  3.49184102e-02\n",
      "  -1.15696547e-01 -2.33994346e-03 -3.51413415e-02  3.87285638e-02\n",
      "  -1.63228615e-03  3.37894039e-03  8.40756361e-02  6.86484910e-02\n",
      "  -2.43054968e-02 -8.49153923e-02 -1.00240162e-02  9.81843897e-03\n",
      "  -2.49569526e-02 -1.09265190e-01 -1.09569451e-02  2.14977332e-03]\n",
      " [ 8.69802261e+00 -2.14456686e+00  4.19787869e+00  6.46294923e+00\n",
      "   1.86646935e+00  2.45106367e+00 -9.35644660e-01 -4.13296409e-01\n",
      "   5.21750876e-01  4.52827301e-01 -4.63272553e-01 -5.99664654e-01\n",
      "   4.21776026e-01 -3.51260797e-01 -3.10533878e-01 -4.78778457e-01\n",
      "   3.80697819e-01  3.87779602e-01  9.49546776e-03  1.85136464e-01\n",
      "   4.58287415e-02 -3.97706502e-01  3.55585274e-01 -1.56012832e-01\n",
      "   2.41130450e-02  2.05563132e-01  1.45953669e-01 -3.26602948e-01\n",
      "  -9.76781400e-02 -1.16817938e-01  1.64373329e-01 -2.37125519e-01\n",
      "   2.20675058e-01 -5.54900535e-02 -1.38281203e-01  8.51088167e-02\n",
      "   2.05304499e-01 -1.31681100e-01  2.31039724e-01 -2.47472791e-02\n",
      "   1.27926121e-01 -1.28332683e-01  3.89895122e-02 -5.49373134e-02\n",
      "   1.73141420e-01  8.78522488e-02  1.84447298e-01  1.24552237e-01\n",
      "  -1.18083535e-01  5.76103282e-02  3.07115828e-02 -1.04584941e-02\n",
      "  -4.13222816e-02 -7.56314190e-02 -1.00675738e-01  8.37851138e-02\n",
      "  -2.52106024e-02  1.31887577e-01 -1.16060152e-01 -1.56749070e-01\n",
      "   1.16010109e-01  3.75786465e-02 -7.31332894e-02  8.50907244e-02\n",
      "   6.12633250e-03 -1.45970074e-02  9.13637219e-02  4.39226472e-02\n",
      "  -1.05071370e-01 -1.15572457e-01 -2.57840301e-02  5.91634895e-02\n",
      "  -1.29991667e-01  1.79192294e-03 -3.24150158e-02 -1.94989817e-01\n",
      "   6.08613921e-02  1.34551541e-01  1.24861459e-01  4.32411170e-02\n",
      "  -5.38769815e-03 -2.16854194e-01 -6.87720295e-02  3.36121498e-02\n",
      "   1.04451664e-01 -9.98096762e-02 -2.51672035e-02 -5.14784006e-02\n",
      "  -6.30023727e-02 -2.64762804e-02 -5.51824505e-02 -1.51564187e-01\n",
      "  -8.97165277e-02 -1.10147896e-01  9.86700399e-02  1.77038150e-03\n",
      "   8.92277241e-02  1.11004161e-03 -5.66349521e-02  1.02410917e-01\n",
      "   5.34025519e-02 -6.43438202e-02  3.59035578e-02  2.51799141e-02\n",
      "   1.10711825e-01  1.04960424e-01  7.87792342e-02 -8.65491660e-02\n",
      "  -8.91039463e-02  1.52982334e-01  7.97205376e-02  9.76551539e-03\n",
      "  -8.82807455e-03  5.95468139e-02 -8.77760919e-02 -1.14823969e-01\n",
      "   1.22356580e-01  1.00457902e-01 -1.45715594e-02 -1.06931222e-01\n",
      "  -1.57047593e-02 -1.20242559e-01 -1.48905442e-01 -4.79276299e-02\n",
      "   9.16572936e-03 -1.01017566e-01 -9.98564367e-02  3.44897395e-02\n",
      "   6.80415952e-02  6.05399788e-02  3.09118203e-03 -2.72989991e-02]\n",
      " [ 3.26056011e-01  1.22440869e+01 -2.09867751e-01 -4.50183770e-01\n",
      "   8.69081171e-01 -8.23146834e-01  4.34116503e-01  1.64321994e+00\n",
      "   4.46525170e-02 -7.79790645e-01  1.98138397e-01 -3.44562399e-01\n",
      "  -1.00165435e-01 -2.71303879e-02  1.29234555e-01  1.20583648e-01\n",
      "   1.47994003e-01  2.75734052e-01 -1.84381237e-01 -1.67928465e-04\n",
      "   5.01011336e-02 -3.34287486e-01 -3.73417892e-01 -3.22828112e-02\n",
      "   2.29679112e-01  9.82723549e-02  1.11119781e-01  1.29196573e-01\n",
      "   9.80159568e-02  2.65008294e-01 -2.68523375e-01 -1.65937762e-01\n",
      "   1.26674452e-01 -1.39063518e-01 -8.39018800e-02 -1.63973877e-01\n",
      "  -3.78471473e-01 -2.70762594e-01  5.89917713e-02 -4.31236149e-02\n",
      "  -2.09070991e-01 -1.34529996e-01  1.72160161e-01  2.31883067e-02\n",
      "   6.40394455e-02 -2.00605077e-01  1.64969713e-01  1.23072905e-01\n",
      "   5.52171026e-02 -5.72042882e-02  1.54128425e-01 -2.26972656e-01\n",
      "   3.75595468e-02 -1.84471750e-01  9.51065577e-02 -1.46275965e-01\n",
      "   1.15819895e-01 -1.05992952e-01 -1.66236065e-01  2.77335155e-02\n",
      "   2.81416323e-02 -4.31744350e-02  3.10360429e-02  1.99183068e-02\n",
      "  -1.16229189e-01 -1.07872078e-01 -1.07287153e-02 -1.15712127e-01\n",
      "   2.49387621e-02 -4.75125745e-02  7.29954950e-02 -3.52362048e-02\n",
      "  -4.75597193e-02 -6.37433655e-02  5.73302201e-02  4.77837731e-02\n",
      "   4.05278662e-02 -1.10604977e-02  1.20066124e-02 -6.62318192e-02\n",
      "  -5.70649979e-02 -1.34479443e-02 -3.23537557e-02  6.40600205e-02\n",
      "  -8.89047805e-03  8.00681049e-02  1.50443294e-02 -9.67202207e-02\n",
      "   8.81423889e-02  1.28458667e-02  1.04928238e-01  1.56739635e-01\n",
      "   3.35368429e-04  1.17916442e-01 -1.12711821e-01 -4.16943614e-02\n",
      "  -1.57481403e-02  4.19043711e-02  8.79358477e-02  3.79204044e-02\n",
      "   3.16030881e-02  7.89806440e-02 -4.38247154e-02  9.54291204e-02\n",
      "  -5.79435447e-03 -8.63138673e-02 -4.28463220e-03  8.71484562e-02\n",
      "  -2.99084224e-03 -1.18948901e-01 -1.63553472e-02  2.87000614e-02\n",
      "   1.53364479e-02 -2.99469109e-02  4.12325125e-02  1.57527460e-01\n",
      "   4.17776347e-02 -3.10716104e-02  2.64828842e-02  8.54825637e-02\n",
      "  -3.73858324e-02  6.20209593e-02 -2.92478415e-02  1.21778221e-02\n",
      "   6.27609883e-02  6.04612990e-02  7.42719836e-02  3.96842175e-03\n",
      "  -1.80352144e-02  9.74321649e-02  2.57529637e-02  1.81131922e-03]\n",
      " [ 1.65746998e+01 -4.49207866e+00 -9.60837130e+00 -4.64193445e+00\n",
      "  -2.94794371e+00 -2.39385085e+00 -6.96963930e-01  3.72147967e-01\n",
      "  -5.24400233e-02  4.55514231e-01  3.68128787e-01  2.07377046e-01\n",
      "  -6.82519427e-02 -3.54368420e-01  6.58647715e-01  1.43223819e-01\n",
      "  -4.60654733e-01  1.27035464e-01  3.37411650e-01  3.43819236e-01\n",
      "  -1.88410026e-01  5.04883986e-01 -2.50563394e-01  3.18880925e-01\n",
      "  -5.36966438e-02 -3.00596329e-01  1.57342113e-01 -4.53063563e-02\n",
      "  -4.53644379e-02 -4.66464691e-03 -5.79696280e-02 -9.94809544e-02\n",
      "   8.68226973e-02  1.95473492e-02 -8.17938963e-02 -3.67859309e-01\n",
      "   9.40035014e-02  2.34497704e-01  3.02127430e-03  1.03258917e-01\n",
      "   1.50244044e-02  1.29990691e-01 -1.08321036e-01  1.25012125e-01\n",
      "   2.72403792e-02 -2.85479652e-01 -1.60371247e-01  3.12903434e-03\n",
      "   4.27012607e-02  5.17910386e-02 -8.98263021e-02  3.47988495e-02\n",
      "  -3.40017236e-02  5.37499916e-02  4.07277418e-04 -4.30473023e-02\n",
      "   1.07075157e-01  4.00146174e-02  8.56278999e-02  5.51508378e-02\n",
      "   2.38354185e-01 -9.51830865e-03  1.32168580e-01  1.26809729e-02\n",
      "  -6.91777062e-02 -2.28432032e-02 -4.78484619e-02 -5.39744031e-02\n",
      "  -7.26096655e-02 -1.43338464e-02  1.75168858e-01 -9.54881738e-03\n",
      "   8.79250126e-02 -6.34543815e-02  2.03697342e-02 -3.12348584e-02\n",
      "  -6.60483902e-02  3.34313110e-02 -1.56502104e-01 -1.15156954e-02\n",
      "  -7.19376522e-02  1.42380586e-01  2.16285599e-02 -3.39830960e-02\n",
      "  -8.06844367e-02  6.88439089e-02  7.18064084e-02  9.66928950e-02\n",
      "  -2.73929183e-02  1.09558760e-01 -2.53554061e-02  5.27670060e-02\n",
      "   3.01249705e-02 -1.11117009e-02 -2.23538548e-02  1.38394016e-01\n",
      "  -5.18744632e-02  2.14756067e-02  8.65148458e-02 -6.63968265e-02\n",
      "  -3.46699725e-03 -2.66664511e-03  3.80001395e-02 -1.88275549e-02\n",
      "  -3.91930238e-02 -2.37995775e-02 -6.64387241e-04  7.95985386e-02\n",
      "   1.77330190e-02 -9.12498376e-02 -1.60289958e-02 -4.73461359e-02\n",
      "  -8.91999138e-03  5.19054490e-02 -4.21326798e-02  7.77732213e-02\n",
      "  -5.03073206e-02 -6.55570615e-03 -8.85485195e-02  1.95676004e-02\n",
      "   2.35728445e-02  6.44286083e-02 -1.01489957e-02  2.46796954e-02\n",
      "  -1.40002860e-02  1.09012759e-01  1.79294640e-02  8.71612516e-03\n",
      "  -8.27517546e-02 -5.39322868e-02  1.02177245e-02 -1.95053325e-02]]\n",
      "Cluster Labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 2 1 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 1 1 1 1 1 1 1 1 1 1 4 4 4 4 4 1 1 0 1 1 0\n",
      " 0 0 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 0 4 4 4 0 0 0 0 0 0 0 0 0 0 0 0 1 0 2 2\n",
      " 2 2 2 2 2 2 2 0 0 2 2 0 0 0 1 1 0 0 0 0 2 0 0 0 0 0 0 0 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 2 2 0 3 3 2 3 3 0 3 3 3 3 3 3 3 3 3 2 3 3 2\n",
      " 3 3 3 3 0 0 0 0 0 0 3 3 3 3 3 0 2 3 2 3 3 3 3 3 3 3 3 3 3 0 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 0 3 3 3 3 3 3 3 3 0 0 0 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 0 0 2 0 0 0 1 0 0 1 0 0 1 1\n",
      " 0 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 2 2 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3\n",
      " 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 0 0 2\n",
      " 1 1 0 0 1 1 1 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1\n",
      " 1 0 1 0 0 0 0 0 0 2 0 0 0 0 0 0 1 1 2 2 2 2 0 0 0 1 1 0 0 1 0 1 1 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 0 0 0 1 1 1 0 0 0 0 0 0 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 2 1 1\n",
      " 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 1 0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 1 1 0 0 2 1 1]\n",
      "For 132 PCA components and 10 clusters:\n",
      "Cluster Centers: [[-7.27425919e+00 -5.31883509e+00  2.75993233e+00 ...  1.15848765e-01\n",
      "  -3.97009469e-02  1.28978040e-01]\n",
      " [-5.87544885e+00 -1.52711870e+00 -1.12837346e+00 ...  5.00944978e-03\n",
      "   6.32481951e-02  2.02326229e-03]\n",
      " [-2.91381682e-02  7.10873406e+00 -1.49218078e+00 ...  1.61751283e-01\n",
      "  -1.81594685e-03  4.38639818e-02]\n",
      " ...\n",
      " [ 7.49595585e+00 -3.07104125e+00  5.27991236e+00 ...  2.38992823e-02\n",
      "  -4.72652504e-03  1.69501835e-03]\n",
      " [ 1.86958048e+00 -2.20756287e+00  1.04614118e+01 ... -2.04110022e-01\n",
      "  -1.82975858e-02 -8.81457937e-02]\n",
      " [ 5.59774619e+00  5.18189583e+00  1.47647485e+00 ... -7.20316189e-03\n",
      "  -1.09578417e-01 -1.81549458e-02]]\n",
      "Cluster Labels: [6 6 1 6 1 0 1 1 1 0 0 0 6 8 8 7 8 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 8 0 8 1 2 2 2 1 8 1 4 4 4 4 4 1 1 2 2 8 0\n",
      " 0 1 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 0 4 4 4 6 1 1 1 1 1 1 1 1 1 0 0 8 0 7 7\n",
      " 7 7 7 7 7 7 7 6 6 7 7 6 6 1 7 8 6 6 6 6 7 6 6 6 6 1 1 6 7 7 6 6 1 2 6 6 6\n",
      " 6 1 1 1 6 1 0 0 1 1 0 0 6 6 6 9 9 6 9 9 9 9 1 1 9 9 9 3 3 3 3 3 9 9 3 3 7\n",
      " 3 9 9 9 1 1 6 6 6 6 3 3 3 2 2 6 7 2 2 2 2 2 2 2 2 2 2 2 2 1 3 3 3 3 3 3 3\n",
      " 3 3 3 3 2 8 2 3 3 3 3 3 3 3 3 3 1 1 1 3 6 3 3 3 2 2 2 2 2 2 6 6 2 2 2 2 2\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 3 3 3 2 2 7 7 1 6 7 1 6 0 8 0 6 0 0 0 8 8\n",
      " 6 7 7 7 7 7 7 7 7 7 7 7 7 7 8 8 7 7 7 7 6 6 6 6 6 6 6 1 6 6 1 6 1 6 6 6 6\n",
      " 2 2 3 3 3 3 3 3 3 3 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 6 7 7 7 7 7 7 7 6 6 7\n",
      " 8 7 6 6 8 8 8 6 6 6 1 1 6 6 1 6 6 1 1 6 6 1 1 1 6 6 6 6 8 1 6 1 1 1 1 8 0\n",
      " 0 0 0 6 6 1 6 1 1 7 1 6 6 6 6 6 7 7 7 7 7 7 6 0 6 8 8 6 6 7 6 0 8 8 6 1 1\n",
      " 6 6 6 1 1 6 6 1 1 6 1 1 6 6 1 1 6 6 1 6 1 1 6 6 1 7 7 7 7 7 7 7 7 7 7 7 7\n",
      " 0 0 0 0 8 0 0 6 1 1 1 1 0 8 0 8 0 0 0 8 8 0 8 0 8 8 8 8 8 0 8 8 8 8 1 8 8\n",
      " 8 8 8 8 8 0 0 0 0 0 0 0 1 8 8 8 1 8 8 0 8 0 1 1 8 0 6 6 6 1 1 1 1 0 6 6 6\n",
      " 0 0 0 0 6 6 1 7 7 7 7 7 7 7 7 7 7 7 8 8 6 6 8 8 8]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Number of clusters to try\n",
    "k_values = [3, 5, 10]\n",
    "\n",
    "# Number of components for PCA\n",
    "pca_components = [3, 7, 19, 132]\n",
    "\n",
    "for num_components in pca_components:\n",
    "    # Apply PCA\n",
    "    pca = PCA(n_components=num_components)\n",
    "    embeddings_pca = pca.fit_transform(embeddings_scaled)\n",
    "    \n",
    "    for k in k_values:\n",
    "        # Apply K-means\n",
    "        kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "        kmeans.fit(embeddings_pca)\n",
    "        \n",
    "        # Your cluster centers\n",
    "        cluster_centers = kmeans.cluster_centers_\n",
    "        \n",
    "        # Your cluster labels for each data point\n",
    "        cluster_labels = kmeans.labels_\n",
    "        \n",
    "        print(f\"For {num_components} PCA components and {k} clusters:\")\n",
    "        print(\"Cluster Centers:\", cluster_centers)\n",
    "        print(\"Cluster Labels:\", cluster_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ad8d50b-66e3-4aad-88d0-082817b1b9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(embedding1, embedding2):\n",
    "    \"\"\"\n",
    "    Calculates the Euclidean distance between two embeddings.\n",
    "    \"\"\"\n",
    "    return np.linalg.norm(np.array(embedding1) - np.array(embedding2))\n",
    "\n",
    "# Initialize an empty list to store the closest embeddings to each cluster center.\n",
    "closest_embeddings_to_centers = []\n",
    "\n",
    "# Make sure your document embeddings are PCA-transformed to have the same number of dimensions as your cluster centers.\n",
    "pca_transformed_embeddings = pca.transform(embeddings)  # Assuming 'pca' is your PCA model and 'embeddings' are your original embeddings\n",
    "\n",
    "# Iterate through each cluster center.\n",
    "for center in cluster_centers:\n",
    "    # Initialize a list to store the distances between the center and each point in the dataset.\n",
    "    distances = []\n",
    "    \n",
    "    # Calculate the distance between the center and each point, and store it in the distances list.\n",
    "    for embedding in pca_transformed_embeddings:\n",
    "        distance = euclidean_distance(center, embedding)\n",
    "        distances.append((embedding, distance))\n",
    "        \n",
    "    # Sort the distances list by the distance value.\n",
    "    distances.sort(key=lambda x: x[1])\n",
    "    \n",
    "    # Take the top 5 closest embeddings to the center.\n",
    "    closest_five_embeddings = [x[0] for x in distances[:5]]\n",
    "    \n",
    "    # Add the closest embeddings to the closest_embeddings_to_centers list.\n",
    "    closest_embeddings_to_centers.append(closest_five_embeddings)\n",
    "\n",
    "# Now closest_embeddings_to_centers[i] will contain the 5 embeddings closest to the i-th cluster center.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0601775c-38ee-46c9-886b-d5c9cac9dbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from IDs to text chunks\n",
    "id_to_text = {str(i+1): text for i, text in enumerate(all_splits)}\n",
    "\n",
    "# Your existing code for finding closest embeddings\n",
    "closest_text_to_centers = []\n",
    "\n",
    "def find_closest_embedding(embedding, all_embeddings):\n",
    "    min_distance = float('inf')\n",
    "    closest_idx = -1\n",
    "    for i, emb in enumerate(all_embeddings):\n",
    "        distance = np.linalg.norm(emb - embedding)\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            closest_idx = i\n",
    "    return closest_idx\n",
    "\n",
    "# Existing code to find closest texts\n",
    "for closest_embeddings in closest_embeddings_to_centers:\n",
    "    closest_text = [id_to_text[str(ids[find_closest_embedding(emb, pca_transformed_embeddings)])] for emb in closest_embeddings]\n",
    "    closest_text_to_centers.append(closest_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd98cd20-f721-4087-84b9-f35ca782590f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thema\\anaconda3\\lib\\site-packages\\transformers\\models\\t5\\tokenization_t5_fast.py:158: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "# Initialize the T5 base model and tokenizer\n",
    "model_name = \"t5-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "# List to store the paraphrased text segments closest to each cluster center\n",
    "paraphrased_text_to_centers = []\n",
    "\n",
    "# Paraphrase the closest text to each cluster center\n",
    "for text_cluster in closest_text_to_centers:\n",
    "    paraphrased_cluster = []\n",
    "    for text in text_cluster:\n",
    "        # Tokenize the text and generate paraphrase\n",
    "        inputs = tokenizer(\"paraphrase: \" + text.page_content, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "        paraphrase_ids = model.generate(inputs.input_ids, max_length=512, num_return_sequences=1)\n",
    "\n",
    "        # Decode the output and add to the list\n",
    "        paraphrased_cluster.append(tokenizer.decode(paraphrase_ids[0], skip_special_tokens=True))\n",
    "        \n",
    "    paraphrased_text_to_centers.append(paraphrased_cluster)\n",
    "\n",
    "# Now, 'paraphrased_text_to_centers' will contain the paraphrased text closest to each cluster center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59ba6d8c-08c2-4ea0-a1e2-6a4b1873391d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Label Distribution: Counter({6: 112, 1: 88, 7: 78, 8: 59, 4: 59, 3: 59, 0: 55, 2: 40, 5: 16, 9: 14})\n",
      "Cluster 0 - Original Texts: [Document(page_content='Encoding for Abstractive Summarization â€” Lin et al.(2018)5. Summarization with Pointer-Generator Networks â€” See et al.(2017)6. Fast Abstractive Summarization with Reinforce-Selected Sentence', metadata={'source': 'https://medium.com/luisfredgs/automatic-text-summarization-with-machine-learning-an-overview-68ded5717a25', 'title': 'Automatic Text Summarization with Machine Learning â€” An overview | by LuÃ\\xads GonÃ§alves | luisfredgs | Medium', 'description': 'Summarization is the task of condensing a piece of text to a shorter version, reducing the size of the initial text while preserving the meaning', 'language': 'en'}), Document(page_content='neural networks â€” Y. Zhang et al. (2016)3. A Neural Attention Model for Abstractive Sentence Summarization â€” Rush et al.(2015)4. Global Encoding for Abstractive Summarization â€” Lin et', metadata={'source': 'https://medium.com/luisfredgs/automatic-text-summarization-with-machine-learning-an-overview-68ded5717a25', 'title': 'Automatic Text Summarization with Machine Learning â€” An overview | by LuÃ\\xads GonÃ§alves | luisfredgs | Medium', 'description': 'Summarization is the task of condensing a piece of text to a shorter version, reducing the size of the initial text while preserving the meaning', 'language': 'en'}), Document(page_content='model for abstractive sentence summarization (NAMAS) by exploring a fully data-driven approach for generating abstractive summaries using an attention-based encoder-decoder method. Attention', metadata={'source': 'https://medium.com/luisfredgs/automatic-text-summarization-with-machine-learning-an-overview-68ded5717a25', 'title': 'Automatic Text Summarization with Machine Learning â€” An overview | by LuÃ\\xads GonÃ§alves | luisfredgs | Medium', 'description': 'Summarization is the task of condensing a piece of text to a shorter version, reducing the size of the initial text while preserving the meaning', 'language': 'en'}), Document(page_content='attention-based sequence to sequence models for abstractive summarization can suffer from repetition and semantic irrelevance, causing grammatical errors and insufficient reflection of the main idea', metadata={'source': 'https://medium.com/luisfredgs/automatic-text-summarization-with-machine-learning-an-overview-68ded5717a25', 'title': 'Automatic Text Summarization with Machine Learning â€” An overview | by LuÃ\\xads GonÃ§alves | luisfredgs | Medium', 'description': 'Summarization is the task of condensing a piece of text to a shorter version, reducing the size of the initial text while preserving the meaning', 'language': 'en'}), Document(page_content='its algorithms requires complicated deep learning techniques and sophisticated language modeling. To generate plausible outputs, abstraction-based summarization approaches must address a wide variety', metadata={'source': 'https://blog.floydhub.com/gentle-introduction-to-text-summarization-in-machine-learning/', 'title': 'A Gentle Introduction to Text Summarization in Machine Learning', 'description': \"Text summarization is a common  in machine learning. In this article, we'll explore how to create a simple extractive text summarization algorithm.\", 'language': 'en'})]\n",
      "Cluster 0 - Paraphrased Texts: ['True', ': neural networks â€” Y. Zhang et al. (2016)2. A Neural Attention Model for Abstractive Sentence Summarization â€” Rush et al. (2015)3. A Neural Attention Model for Abstractive Sentence Summarization â€” Rush et al. (2015)4. A Neural Attention Model for Abstractive Sentence Summarization â€” Rush et al. (2015)5. A Neural Attention Model for Abstractive Sentence Summarization â', 'positive', 'False', 'False']\n",
      "Cluster 1 - Original Texts: [Document(page_content='systems as an intermediate stage which helps to reduce the length of the document.Text identification, interpretation and summary generation, and analysis of the generated summary are some of the key', metadata={'source': 'https://medium.com/@dilip.voleti/concept-of-text-summarization-3745ffc8d84e', 'title': 'Concept of Text Summarization. In this article we are going to explain… | by Dilip Valeti | Medium', 'description': 'In this article we are going to explain importance of Text Summarization and it’s considerable impact on our lives. Text summarization is an important Natural Language Processing (NLP) task . With…', 'language': 'en'}), Document(page_content='conveys the most critical information from the original text, requiring rephrasing sentences and incorporating information from full text to generate summaries such as a human-written abstract', metadata={'source': 'https://medium.com/@dilip.voleti/concept-of-text-summarization-3745ffc8d84e', 'title': 'Concept of Text Summarization. In this article we are going to explain… | by Dilip Valeti | Medium', 'description': 'In this article we are going to explain importance of Text Summarization and it’s considerable impact on our lives. Text summarization is an important Natural Language Processing (NLP) task . With…', 'language': 'en'}), Document(page_content='original document, that conveys the most critical information from the original text, requiring rephrasing sentences and incorporating information from full text to generate summaries such as a', metadata={'source': 'https://medium.com/luisfredgs/automatic-text-summarization-with-machine-learning-an-overview-68ded5717a25', 'title': 'Automatic Text Summarization with Machine Learning â€” An overview | by LuÃ\\xads GonÃ§alves | luisfredgs | Medium', 'description': 'Summarization is the task of condensing a piece of text to a shorter version, reducing the size of the initial text while preserving the meaning', 'language': 'en'}), Document(page_content='the important sentences or phrases from the original text and stitch together portions of the content to produce a condensed version. These extracted sentences are then used to form the summary.Thus,', metadata={'source': 'https://medium.com/@dilip.voleti/concept-of-text-summarization-3745ffc8d84e', 'title': 'Concept of Text Summarization. In this article we are going to explain… | by Dilip Valeti | Medium', 'description': 'In this article we are going to explain importance of Text Summarization and it’s considerable impact on our lives. Text summarization is an important Natural Language Processing (NLP) task . With…', 'language': 'en'}), Document(page_content='directly from the document based on a scoring function to form a coherent summary. This method work by identifying important sections of the text cropping out and stitch together portions of the', metadata={'source': 'https://medium.com/@dilip.voleti/concept-of-text-summarization-3745ffc8d84e', 'title': 'Concept of Text Summarization. In this article we are going to explain… | by Dilip Valeti | Medium', 'description': 'In this article we are going to explain importance of Text Summarization and it’s considerable impact on our lives. Text summarization is an important Natural Language Processing (NLP) task . With…', 'language': 'en'})]\n",
      "Cluster 1 - Paraphrased Texts: [':::: stages of the document. key stages of the document. stages of the document... stages of the document.  intermediate stages which helps to reduce the length of the document.. the document. stages which help to reduce the length of the document. stages. stages. stages. key stages..: stages. stages. stages. stages. stages. stages. stages of the document.Text', 'True', 'True', 'False', ':::: text the text. text to form a coherent summary. a scoring function to form a coherent summary. summary text. based on a scoring function to form a coherent summary. summary text. based on a scoring function to form a coherent summary. text. text text text. text the text: text text text. text. text. text. text. This method']\n",
      "Cluster 2 - Original Texts: [Document(page_content=\"article_read = fetched_data.read()\\n\\n# Parsing the URL content and storing in a variable\\narticle_parsed = BeautifulSoup.BeautifulSoup(article_read,'html.parser')\", metadata={'source': 'https://blog.floydhub.com/gentle-introduction-to-text-summarization-in-machine-learning/', 'title': 'A Gentle Introduction to Text Summarization in Machine Learning', 'description': \"Text summarization is a common  in machine learning. In this article, we'll explore how to create a simple extractive text summarization algorithm.\", 'language': 'en'}), Document(page_content=\"article_read = fetched_data.read()\\n\\n# Parsing the URL content and storing in a variable\\narticle_parsed = BeautifulSoup.BeautifulSoup(article_read,'html.parser')\", metadata={'source': 'https://blog.floydhub.com/gentle-introduction-to-text-summarization-in-machine-learning/', 'title': 'A Gentle Introduction to Text Summarization in Machine Learning', 'description': \"Text summarization is a common  in machine learning. In this article, we'll explore how to create a simple extractive text summarization algorithm.\", 'language': 'en'}), Document(page_content=\"# Fetching the content from the URL\\nfetched_data = urllib.request.urlopen('https://en.wikipedia.org/wiki/20th_century')\\n\\narticle_read = fetched_data.read()\", metadata={'source': 'https://blog.floydhub.com/gentle-introduction-to-text-summarization-in-machine-learning/', 'title': 'A Gentle Introduction to Text Summarization in Machine Learning', 'description': \"Text summarization is a common  in machine learning. In this article, we'll explore how to create a simple extractive text summarization algorithm.\", 'language': 'en'}), Document(page_content=\"#fetching the content from the URL\\nfetched_data = urllib.request.urlopen('https://en.wikipedia.org/wiki/20th_century')\\n\\narticle_read = fetched_data.read()\", metadata={'source': 'https://blog.floydhub.com/gentle-introduction-to-text-summarization-in-machine-learning/', 'title': 'A Gentle Introduction to Text Summarization in Machine Learning', 'description': \"Text summarization is a common  in machine learning. In this article, we'll explore how to create a simple extractive text summarization algorithm.\", 'language': 'en'}), Document(page_content=\"# Returning <p> tags\\nparagraphs = article_parsed.find_all('p')\\n\\narticle_content = ''\", metadata={'source': 'https://blog.floydhub.com/gentle-introduction-to-text-summarization-in-machine-learning/', 'title': 'A Gentle Introduction to Text Summarization in Machine Learning', 'description': \"Text summarization is a common  in machine learning. In this article, we'll explore how to create a simple extractive text summarization algorithm.\", 'language': 'en'})]\n",
      "Cluster 2 - Paraphrased Texts: ['True', 'True', 'False', 'False', 'False']\n",
      "Cluster 3 - Original Texts: [Document(page_content='for word_weight in frequency_table:\\n            if word_weight in sentence.lower():\\n                sentence_wordcount_without_stop_words += 1', metadata={'source': 'https://blog.floydhub.com/gentle-introduction-to-text-summarization-in-machine-learning/', 'title': 'A Gentle Introduction to Text Summarization in Machine Learning', 'description': \"Text summarization is a common  in machine learning. In this article, we'll explore how to create a simple extractive text summarization algorithm.\", 'language': 'en'}), Document(page_content='for word_weight in frequency_table:\\n            if word_weight in sentence.lower():\\n                sentence_wordcount_without_stop_words += 1', metadata={'source': 'https://blog.floydhub.com/gentle-introduction-to-text-summarization-in-machine-learning/', 'title': 'A Gentle Introduction to Text Summarization in Machine Learning', 'description': \"Text summarization is a common  in machine learning. In this article, we'll explore how to create a simple extractive text summarization algorithm.\", 'language': 'en'}), Document(page_content='else:\\n                    sentence_weight[sentence[:7]] = frequency_table[word_weight]', metadata={'source': 'https://blog.floydhub.com/gentle-introduction-to-text-summarization-in-machine-learning/', 'title': 'A Gentle Introduction to Text Summarization in Machine Learning', 'description': \"Text summarization is a common  in machine learning. In this article, we'll explore how to create a simple extractive text summarization algorithm.\", 'language': 'en'}), Document(page_content='else:\\n                    sentence_weight[sentence[:7]] = frequency_table[word_weight]', metadata={'source': 'https://blog.floydhub.com/gentle-introduction-to-text-summarization-in-machine-learning/', 'title': 'A Gentle Introduction to Text Summarization in Machine Learning', 'description': \"Text summarization is a common  in machine learning. In this article, we'll explore how to create a simple extractive text summarization algorithm.\", 'language': 'en'}), Document(page_content='if sentence[:7] in sentence_weight:\\n                    sentence_weight[sentence[:7]] += frequency_table[word_weight]\\n                else:', metadata={'source': 'https://blog.floydhub.com/gentle-introduction-to-text-summarization-in-machine-learning/', 'title': 'A Gentle Introduction to Text Summarization in Machine Learning', 'description': \"Text summarization is a common  in machine learning. In this article, we'll explore how to create a simple extractive text summarization algorithm.\", 'language': 'en'})]\n",
      "Cluster 3 - Paraphrased Texts: ['False', 'False', 'negative', 'negative', 'True']\n",
      "Cluster 4 - Original Texts: [Document(page_content=\"service's allure to subscribers, so that's likely out, too, at least for now.So if Netflix is looking for other forms of near-term revenue to help support its hefty content budget ($17 billion in\", metadata={'source': 'https://towardsdatascience.com/the-secret-guide-to-human-like-text-summarization-fcea0bfbe801', 'title': 'The Secret Guide To Human-Like Text Summarization | by Louis Teo | Medium | Towards Data Science', 'description': \"Summarization has become a very helpful way of tackling the issue of data overburden. Use Google's state-of-the-art T5 model to build a simple yet powerful text summarizer.\", 'language': 'en'}), Document(page_content='Netflix service. His reasoning: It doesn\\'t make business sense.\"It\\'s a judgment call... It\\'s a belief we can build a better business, a more valuable business [without advertising],\" Hastings told', metadata={'source': 'https://towardsdatascience.com/the-secret-guide-to-human-like-text-summarization-fcea0bfbe801', 'title': 'The Secret Guide To Human-Like Text Summarization | by Louis Teo | Medium | Towards Data Science', 'description': \"Summarization has become a very helpful way of tackling the issue of data overburden. Use Google's state-of-the-art T5 model to build a simple yet powerful text summarizer.\", 'language': 'en'}), Document(page_content='and died with its subscriber numbers - started thinking about other ways to make money. Not so fastThere are ways for Netflix to make money other than raising prices or adding subscribers. His', metadata={'source': 'https://towardsdatascience.com/the-secret-guide-to-human-like-text-summarization-fcea0bfbe801', 'title': 'The Secret Guide To Human-Like Text Summarization | by Louis Teo | Medium | Towards Data Science', 'description': \"Summarization has become a very helpful way of tackling the issue of data overburden. Use Google's state-of-the-art T5 model to build a simple yet powerful text summarizer.\", 'language': 'en'}), Document(page_content=\"subscriber misses before and it's still the most dominant name in all of streaming, and even lackluster growth is still growth. It's not as if people are canceling Netflix in droves.Asked about\", metadata={'source': 'https://towardsdatascience.com/the-secret-guide-to-human-like-text-summarization-fcea0bfbe801', 'title': 'The Secret Guide To Human-Like Text Summarization | by Louis Teo | Medium | Towards Data Science', 'description': \"Summarization has become a very helpful way of tackling the issue of data overburden. Use Google's state-of-the-art T5 model to build a simple yet powerful text summarizer.\", 'language': 'en'}), Document(page_content='level of penetration, definitely, but not in long-term.\"Lackluster growth is still growthMissing projections is never good, but it\\'s hardly the end of the world for Netflix. The company remains the', metadata={'source': 'https://towardsdatascience.com/the-secret-guide-to-human-like-text-summarization-fcea0bfbe801', 'title': 'The Secret Guide To Human-Like Text Summarization | by Louis Teo | Medium | Towards Data Science', 'description': \"Summarization has become a very helpful way of tackling the issue of data overburden. Use Google's state-of-the-art T5 model to build a simple yet powerful text summarizer.\", 'language': 'en'})]\n",
      "Cluster 4 - Paraphrased Texts: [\"Netflix is looking for other forms of near-term revenue to help support its hefty content budget. if it's looking for other forms of revenue to help support its hefty content budget, that's likely out.\", 'False', 'Netflix has been a huge success since its inception in 2004.', 'True', \"Netflix remains the company that is booming, but not in long-term. the company is a leader in streaming video, but it's not the end of the world.\"]\n",
      "Cluster 5 - Original Texts: [Document(page_content='them in very different parts of my life.I think everyone just thinks because weâ€™re tennis players we should be the greatest of friends. But ultimately tennis is just a very small part of what we', metadata={'source': 'https://medium.com/analytics-vidhya/text-summarization-using-nlp-3e85ad0c6349', 'title': 'Text summarization using NLP. Text summarization is the process ofâ€¦ | by Anoop Singh | Analytics Vidhya | Medium', 'description': 'Text summarization is the process of generating short, fluent, and most importantly accurate summary of a respectively longer text document. The main idea behind automatic text summarization is to beâ€¦', 'language': 'en'}), Document(page_content='summaryI think just because youâ€™re in the same sport doesnâ€™t mean that you have to be friends with everyone just because youâ€™re categorized, youâ€™re a tennis player, so youâ€™re going to get', metadata={'source': 'https://medium.com/analytics-vidhya/text-summarization-using-nlp-3e85ad0c6349', 'title': 'Text summarization using NLP. Text summarization is the process ofâ€¦ | by Anoop Singh | Analytics Vidhya | Medium', 'description': 'Text summarization is the process of generating short, fluent, and most importantly accurate summary of a respectively longer text document. The main idea behind automatic text summarization is to beâ€¦', 'language': 'en'}), Document(page_content='that she is doing? Is it different on the menâ€™s tour than the womenâ€™s tour? â€˜No, not at all.I think just because youâ€™re in the same sport doesnâ€™t mean that you have to be friends with', metadata={'source': 'https://medium.com/analytics-vidhya/text-summarization-using-nlp-3e85ad0c6349', 'title': 'Text summarization using NLP. Text summarization is the process ofâ€¦ | by Anoop Singh | Analytics Vidhya | Medium', 'description': 'Text summarization is the process of generating short, fluent, and most importantly accurate summary of a respectively longer text document. The main idea behind automatic text summarization is to beâ€¦', 'language': 'en'}), Document(page_content='a tennis player, so youâ€™re going to get along with tennis players. Maria Sharapova has basically no friends as tennis players on the WTA Tour. I have friends that have completely different jobs and', metadata={'source': 'https://medium.com/analytics-vidhya/text-summarization-using-nlp-3e85ad0c6349', 'title': 'Text summarization using NLP. Text summarization is the process ofâ€¦ | by Anoop Singh | Analytics Vidhya | Medium', 'description': 'Text summarization is the process of generating short, fluent, and most importantly accurate summary of a respectively longer text document. The main idea behind automatic text summarization is to beâ€¦', 'language': 'en'}), Document(page_content='friends that have completely different jobs and interests, and Iâ€™ve met them in very different parts of my life. I think everyone just thinks because weâ€™re tennis players So Iâ€™m not the one to', metadata={'source': 'https://medium.com/analytics-vidhya/text-summarization-using-nlp-3e85ad0c6349', 'title': 'Text summarization using NLP. Text summarization is the process ofâ€¦ | by Anoop Singh | Analytics Vidhya | Medium', 'description': 'Text summarization is the process of generating short, fluent, and most importantly accurate summary of a respectively longer text document. The main idea behind automatic text summarization is to beâ€¦', 'language': 'en'})]\n",
      "Cluster 5 - Paraphrased Texts: ['tennis is just a very small part of what weâ€TMre all about. iâ€TMm not a tennis player, but a tennis player.', 'True', \"bob greene: menâ€TMs tour is different from womenâ€TMs tour. he says menâ€TMs tour is different, but not different. greene: menâ€TMs tour is different, but women's tour is different. greene: menâ€TMs tour is different, but men's tour is different.\", 'tennis players are going to get along with tennis players, says adam saatchi. saatchi is a professional tennis player, so youâ€TMre going to get along with tennis players. saatchi is a professional tennis player, so youâ€TMre going to get along with tennis players.', 'bob greene: Iâ€TMve met friends that have completely different jobs and interests. greene: Iâ€TMve met people that have completely different jobs and interests. he says people think weâ€TMre tennis players, and Iâ€TMm not the one to blame. greene: Iâ€TMm not the one to blame because weâ€TMre tennis players.']\n",
      "Cluster 6 - Original Texts: [Document(page_content='is a need to develop automatic text summarization tools that allow people to get insights from them easily. Currently, we enjoy quick access to enormous amounts of information. However, most of this', metadata={'source': 'https://blog.floydhub.com/gentle-introduction-to-text-summarization-in-machine-learning/', 'title': 'A Gentle Introduction to Text Summarization in Machine Learning', 'description': \"Text summarization is a common  in machine learning. In this article, we'll explore how to create a simple extractive text summarization algorithm.\", 'language': 'en'}), Document(page_content='research in the NLP area for automatic text summarization. Automatic text summarization is the task of producing a concise and fluent summary without any human help while preserving the meaning of', metadata={'source': 'https://medium.com/luisfredgs/automatic-text-summarization-with-machine-learning-an-overview-68ded5717a25', 'title': 'Automatic Text Summarization with Machine Learning â€” An overview | by LuÃ\\xads GonÃ§alves | luisfredgs | Medium', 'description': 'Summarization is the task of condensing a piece of text to a shorter version, reducing the size of the initial text while preserving the meaning', 'language': 'en'}), Document(page_content='The need for text summarizationWith the present explosion of data circulating the digital space, which is mostly non-structured textual data, there is a need to develop automatic text summarization', metadata={'source': 'https://blog.floydhub.com/gentle-introduction-to-text-summarization-in-machine-learning/', 'title': 'A Gentle Introduction to Text Summarization in Machine Learning', 'description': \"Text summarization is a common  in machine learning. In this article, we'll explore how to create a simple extractive text summarization algorithm.\", 'language': 'en'}), Document(page_content='hope this post helped you in understanding the concept of automatic text summarization. It has an introduction to Extractive and Abstractive Summarization techniques, as the text summarization is an', metadata={'source': 'https://medium.com/@dilip.voleti/concept-of-text-summarization-3745ffc8d84e', 'title': 'Concept of Text Summarization. In this article we are going to explain… | by Dilip Valeti | Medium', 'description': 'In this article we are going to explain importance of Text Summarization and it’s considerable impact on our lives. Text summarization is an important Natural Language Processing (NLP) task . With…', 'language': 'en'}), Document(page_content='of the generated summary are some of the key challenges faced in the process of text summarization. Two different approaches that are used for text summarization are:Extractive', metadata={'source': 'https://medium.com/@dilip.voleti/concept-of-text-summarization-3745ffc8d84e', 'title': 'Concept of Text Summarization. In this article we are going to explain… | by Dilip Valeti | Medium', 'description': 'In this article we are going to explain importance of Text Summarization and it’s considerable impact on our lives. Text summarization is an important Natural Language Processing (NLP) task . With…', 'language': 'en'})]\n",
      "Cluster 6 - Paraphrased Texts: [':: is a need to develop automatic text summarization tools that allow people to get insights from them easily. This is a paraphrase: is a need to develop automatic text summarization tools that allow people to get insights from them easily.', 'False', 'True', 'True', 'True']\n",
      "Cluster 7 - Original Texts: [Document(page_content='of this article. You guys rock!Do you model for living? ğŸ‘©â€�ğŸ’» ğŸ¤– Be part of a ML/DL user research study and get a cool AI t-shirt every month ğŸ’¥We are looking for full-time data scientists', metadata={'source': 'https://blog.floydhub.com/gentle-introduction-to-text-summarization-in-machine-learning/', 'title': 'A Gentle Introduction to Text Summarization in Machine Learning', 'description': \"Text summarization is a common  in machine learning. In this article, we'll explore how to create a simple extractive text summarization algorithm.\", 'language': 'en'}), Document(page_content=\"ğŸ’¥We are looking for full-time data scientists for a ML/DL user study. You'll be participating in a calibrated user research experiment for 45 minutes. The study will be done over a video call.\", metadata={'source': 'https://blog.floydhub.com/gentle-introduction-to-text-summarization-in-machine-learning/', 'title': 'A Gentle Introduction to Text Summarization in Machine Learning', 'description': \"Text summarization is a common  in machine learning. In this article, we'll explore how to create a simple extractive text summarization algorithm.\", 'language': 'en'}), Document(page_content='and engineering journals.Data ScienceArtificial IntelligenceMachine LearningTechnologyProgramming----3FollowWritten by Louis Teo92 FollowersÂ·Writer for Towards Data ScienceAn engineer whoâ€™s into', metadata={'source': 'https://towardsdatascience.com/the-secret-guide-to-human-like-text-summarization-fcea0bfbe801', 'title': 'The Secret Guide To Human-Like Text Summarization | by Louis Teo | Medium | Towards Data Science', 'description': \"Summarization has become a very helpful way of tackling the issue of data overburden. Use Google's state-of-the-art T5 model to build a simple yet powerful text summarizer.\", 'language': 'en'}), Document(page_content='GonÃ§alvesinluisfredgsMestrado em CiÃªncia da ComputaÃ§Ã£o, na Ã¡rea de Machine Learning, que tal tentar?Nesse post eu conto um pouco sobre os motivos que me levaram a cursar um mestrado acadÃªmico', metadata={'source': 'https://medium.com/luisfredgs/automatic-text-summarization-with-machine-learning-an-overview-68ded5717a25', 'title': 'Automatic Text Summarization with Machine Learning â€” An overview | by LuÃ\\xads GonÃ§alves | luisfredgs | Medium', 'description': 'Summarization is the task of condensing a piece of text to a shorter version, reducing the size of the initial text while preserving the meaning', 'language': 'en'}), Document(page_content='Is the Best Tool to Boost Your LLM Application?The definitive guide for choosing the right method for your use caseÂ·19 min readÂ·Aug 24--16Giuseppe ScalamognainTowards Data ScienceNew ChatGPT Prompt', metadata={'source': 'https://towardsdatascience.com/the-secret-guide-to-human-like-text-summarization-fcea0bfbe801', 'title': 'The Secret Guide To Human-Like Text Summarization | by Louis Teo | Medium | Towards Data Science', 'description': \"Summarization has become a very helpful way of tackling the issue of data overburden. Use Google's state-of-the-art T5 model to build a simple yet powerful text summarizer.\", 'language': 'en'})]\n",
      "Cluster 7 - Paraphrased Texts: ['True', 'True', 'True', 'False', 'True']\n",
      "Cluster 8 - Original Texts: [Document(page_content='a unique two-stage model that is based on a sequence-to-sequence paradigm. The model makes use of BERT (you can bet that we will continue to read about BERT in all 2019) on both encoder and decoder', metadata={'source': 'https://blog.floydhub.com/gentle-introduction-to-text-summarization-in-machine-learning/', 'title': 'A Gentle Introduction to Text Summarization in Machine Learning', 'description': \"Text summarization is a common  in machine learning. In this article, we'll explore how to create a simple extractive text summarization algorithm.\", 'language': 'en'}), Document(page_content='each time step, which is a CNN that convolves all the encoder outputs, in order to tackle this problem.Based on the convolution and self-attention of Vaswani et al., a convolutional gated unit sets a', metadata={'source': 'https://medium.com/luisfredgs/automatic-text-summarization-with-machine-learning-an-overview-68ded5717a25', 'title': 'Automatic Text Summarization with Machine Learning â€” An overview | by LuÃ\\xads GonÃ§alves | luisfredgs | Medium', 'description': 'Summarization is the task of condensing a piece of text to a shorter version, reducing the size of the initial text while preserving the meaning', 'language': 'en'}), Document(page_content='Vaswani et al., a convolutional gated unit sets a gate to filter the source annotations from the RNN encoder, in order to select information relevant to the global semantic meaning. In other words,', metadata={'source': 'https://medium.com/luisfredgs/automatic-text-summarization-with-machine-learning-an-overview-68ded5717a25', 'title': 'Automatic Text Summarization with Machine Learning â€” An overview | by LuÃ\\xads GonÃ§alves | luisfredgs | Medium', 'description': 'Summarization is the task of condensing a piece of text to a shorter version, reducing the size of the initial text while preserving the meaning', 'language': 'en'}), Document(page_content='BERT in all 2019) on both encoder and decoder sides and focuses on reinforced objective during the learning process. When the model was assessed on some benchmark datasets, the outcome revealed that', metadata={'source': 'https://blog.floydhub.com/gentle-introduction-to-text-summarization-in-machine-learning/', 'title': 'A Gentle Introduction to Text Summarization in Machine Learning', 'description': \"Text summarization is a common  in machine learning. In this article, we'll explore how to create a simple extractive text summarization algorithm.\", 'language': 'en'}), Document(page_content='faster than the previous state-of-the-art. Both source code and best pre-trained models were released to promote future research.Other recent studies have proposed using a combination of the', metadata={'source': 'https://medium.com/luisfredgs/automatic-text-summarization-with-machine-learning-an-overview-68ded5717a25', 'title': 'Automatic Text Summarization with Machine Learning â€” An overview | by LuÃ\\xads GonÃ§alves | luisfredgs | Medium', 'description': 'Summarization is the task of condensing a piece of text to a shorter version, reducing the size of the initial text while preserving the meaning', 'language': 'en'})]\n",
      "Cluster 8 - Paraphrased Texts: ['a unique two-stage model that is based on a sequence-to-sequence paradigm. the model uses BERT on both encoder and decoder. it uses a sequence-to-sequence paradigm on both encoder and decoder.', 'True', 'True', 'False', ': : faster than the previous state-the-art.  two two. two. two. two. two. two. two. two.. two. two. source code and best pre-trained models were released to promote future research. two. source code and best pre-trained models were released to promote future research. source code: two two. two. two. two. two. two']\n",
      "Cluster 9 - Original Texts: [Document(page_content='and was rushed to the hospital 3. Since she was diagnosed with a brain injury, the doctor told Peter to stay besides her until she gets well4. Therefore, Peter stayed with her at the hospital for 3', metadata={'source': 'https://blog.floydhub.com/gentle-introduction-to-text-summarization-in-machine-learning/', 'title': 'A Gentle Introduction to Text Summarization in Machine Learning', 'description': \"Text summarization is a common  in machine learning. In this article, we'll explore how to create a simple extractive text summarization algorithm.\", 'language': 'en'}), Document(page_content='4\\nTherefore, Peter stayed with her at the hospital for 3 days without leaving\\n1 + 0.67 + 0.67 + 0.33 + 0.33 + 0.33\\n3.33', metadata={'source': 'https://blog.floydhub.com/gentle-introduction-to-text-summarization-in-machine-learning/', 'title': 'A Gentle Introduction to Text Summarization in Machine Learning', 'description': \"Text summarization is a common  in machine learning. In this article, we'll explore how to create a simple extractive text summarization algorithm.\", 'language': 'en'}), Document(page_content='took a taxi to attend the night party in the city. While in the party, Elizabeth collapsed and was rushed to the hospital. Since she was diagnosed with a brain injury, the doctor told Peter to stay', metadata={'source': 'https://blog.floydhub.com/gentle-introduction-to-text-summarization-in-machine-learning/', 'title': 'A Gentle Introduction to Text Summarization in Machine Learning', 'description': \"Text summarization is a common  in machine learning. In this article, we'll explore how to create a simple extractive text summarization algorithm.\", 'language': 'en'}), Document(page_content='a brain injury, the doctor told Peter to stay besides her until she gets well. Therefore, Peter stayed with her at the hospital for 3 days without leaving.â€�Here are the steps to follow to summarize', metadata={'source': 'https://blog.floydhub.com/gentle-introduction-to-text-summarization-in-machine-learning/', 'title': 'A Gentle Introduction to Text Summarization in Machine Learning', 'description': \"Text summarization is a common  in machine learning. In this article, we'll explore how to create a simple extractive text summarization algorithm.\", 'language': 'en'}), Document(page_content='3\\nSince she was diagnosed with a brain injury, the doctor told Peter to stay besides her until she gets well.\\n0.33 + 0.33 + 0.33 + 0.33 + 1 + 0.33 + 0.33 + 0.33 + 0.33 +0.33\\n3.97', metadata={'source': 'https://blog.floydhub.com/gentle-introduction-to-text-summarization-in-machine-learning/', 'title': 'A Gentle Introduction to Text Summarization in Machine Learning', 'description': \"Text summarization is a common  in machine learning. In this article, we'll explore how to create a simple extractive text summarization algorithm.\", 'language': 'en'})]\n",
      "Cluster 9 - Paraphrased Texts: ['True', 'False', 'Peter took a taxi to attend the night party in the city. while in the party, Elizabeth collapsed and was rushed to the hospital. Peter told Peter to stay at home and not go to the hospital.', 'a brain injury, the doctor told Peter to stay besides her until she gets well. therefore, Peter stayed with her at the hospital for 3 days without leaving.', 'True']\n",
      "Manually compare the original and paraphrased texts displayed above.\n",
      "\n",
      "Step 4: Variability Across Different PCA and K-means Settings\n",
      "Cluster Labels for 3 PCA components and 3 clusters: [0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 2 0 2 2 2 0 1 0 1 1 1 1 1 1 2 0 2 1 0\n",
      " 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1\n",
      " 1 1 1 1 1 1 1 0 0 1 1 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0 0\n",
      " 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 1 1 0 2 1 1 2 2 1 2 2 2 2 2 2 2 2 1 1 2 2 1\n",
      " 2 2 2 2 2 0 0 0 0 0 2 2 2 2 2 0 1 2 1 2 2 2 2 2 1 1 1 2 2 0 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 0 0 0 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 0 0 1 0 0 0 1 0 0 0 0 0 1 1\n",
      " 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2\n",
      " 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1\n",
      " 1 0 0 0 1 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 0 0 1 0 0 1 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 1 1 1 1 1 0 1 1 1 0 1 1 1\n",
      " 1 1 1 1 0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1]\n",
      "Cluster Labels for 3 PCA components and 5 clusters: [1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 4 2 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 4 0 0 0 0 0 0 0 0 4 0 2 1 2 2 3 3 3 1 2 1 4 0 0 0 4 2 2 1 3 2 1\n",
      " 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 4 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 4\n",
      " 2 2 4 4 4 4 4 1 1 2 4 1 1 2 2 2 1 1 1 1 4 1 1 1 1 1 1 1 2 4 1 1 4 4 1 1 1\n",
      " 1 1 1 1 3 1 1 2 1 1 1 1 1 1 1 4 4 1 3 4 4 3 3 4 2 3 3 3 3 3 3 3 4 4 3 3 4\n",
      " 3 4 4 4 3 1 1 1 1 1 3 3 3 3 3 1 4 3 4 4 3 3 3 4 4 4 4 3 3 2 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 1 3 3 3 3 3 3 3 3 1 1 1 3 4 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 2 1 1 4 1 1 1 2 1 1 2 1 1 2 2\n",
      " 1 4 4 4 4 2 2 2 2 2 2 2 4 4 2 2 4 4 4 4 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3\n",
      " 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 1 4 4 4 4 4 2 4 1 1 4\n",
      " 2 2 1 1 2 2 2 1 1 1 4 4 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 1\n",
      " 1 1 1 1 1 1 1 1 1 4 1 1 1 1 1 1 2 2 4 2 4 4 1 1 1 2 2 1 1 2 1 2 2 2 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 4 4 4 4 4 4 2 4 4 4 4 4\n",
      " 1 1 1 2 2 1 1 1 1 1 1 1 1 2 1 2 1 1 1 2 2 1 2 1 2 2 2 2 2 1 2 2 2 2 2 2 2\n",
      " 2 2 2 2 1 1 2 1 2 1 2 2 1 2 2 2 1 2 2 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 2 2 2 2 2 4 4 2 4 2 2 2 2 1 1 2 2 2]\n",
      "Cluster Labels for 3 PCA components and 10 clusters: [2 9 9 2 9 9 9 2 2 9 2 9 8 1 7 5 7 4 3 3 3 3 3 3 3 4 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 4 3 3 3 3 3 3 3 3 4 3 1 1 6 1 6 6 6 1 1 9 4 3 3 3 4 1 6 8 6 7 9\n",
      " 8 8 3 3 3 3 3 3 3 3 3 3 4 3 3 3 3 9 3 3 4 8 9 2 2 9 2 8 8 8 2 9 9 7 9 7 5\n",
      " 5 5 5 5 5 5 5 9 9 7 4 2 9 1 1 7 9 9 2 2 5 2 2 2 2 9 9 2 7 4 2 2 6 6 2 2 2\n",
      " 2 2 2 2 8 8 9 1 9 9 9 9 9 2 2 4 4 2 8 6 4 6 6 6 6 6 6 0 0 0 0 0 6 4 0 0 4\n",
      " 0 6 6 6 8 8 8 9 2 8 8 0 0 8 8 8 4 6 4 6 6 6 8 6 6 6 6 6 6 1 6 6 0 0 0 6 0\n",
      " 0 0 0 0 8 6 6 0 0 0 0 0 0 0 0 0 6 8 8 6 2 0 0 0 8 8 8 8 8 8 9 9 6 6 6 6 8\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 8 8 8 0 0 0 8 8 4 5 8 2 5 2 2 9 7 9 2 1 9 9 7 7\n",
      " 2 5 5 5 4 5 5 5 7 7 5 5 4 4 7 7 5 5 5 5 2 2 2 2 2 2 2 2 2 2 9 2 2 2 2 2 8\n",
      " 6 6 0 0 0 0 0 0 0 8 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 9 5 4 4 6 4 5 5 9 9 5\n",
      " 1 1 8 9 7 1 1 2 2 2 5 5 2 2 9 2 2 2 9 2 2 2 2 2 2 2 2 2 1 8 2 2 9 9 9 7 9\n",
      " 9 9 9 9 2 2 2 2 9 5 9 2 2 2 2 2 7 1 5 5 5 5 9 9 9 1 7 2 9 1 1 9 7 7 2 9 9\n",
      " 2 2 9 2 1 2 2 9 9 2 2 9 2 2 2 9 2 2 2 2 1 8 8 2 8 5 5 4 4 4 5 5 5 5 5 5 4\n",
      " 9 9 9 1 7 9 9 9 9 2 9 9 9 7 9 1 9 9 9 7 7 9 1 9 7 7 7 1 7 9 7 7 7 1 1 7 7\n",
      " 7 7 1 1 9 9 1 9 9 9 1 1 9 1 1 1 1 7 7 9 7 9 9 9 7 9 9 2 2 2 2 9 9 9 9 2 2\n",
      " 9 9 9 9 2 2 9 7 7 5 7 1 5 5 1 5 7 7 7 1 9 2 5 7 1]\n",
      "Cluster Labels for 7 PCA components and 3 clusters: [0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 0 2 0 2 2 2 0 2 0 1 1 1 1 1 2 2 0 2 2 0\n",
      " 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 2 0 2 2\n",
      " 2 2 2 2 2 2 2 0 0 2 2 0 0 2 2 2 0 0 0 0 2 0 0 0 0 0 0 0 2 2 0 0 2 2 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 0 0 0 0 0 0 2 2 2 2 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 0 0 2 0 0 0 0 0 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 2 2 2 0 0 2 2 0 0 2 0 0 0 2 0 0 2 0 0 2 2\n",
      " 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 0 0 2\n",
      " 2 2 0 0 2 2 2 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0\n",
      " 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 2 2 2 2 2 0 0 0 2 2 0 0 2 0 0 2 2 0 0 0\n",
      " 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 0 0 0 2 2 0 0 0 0 0 0 0 0 2 0 2 0 0 0 2 2 0 0 0 2 2 2 2 2 0 2 2 2 2 2 2 2\n",
      " 2 2 2 2 0 0 0 0 0 0 2 0 0 2 2 2 0 2 2 0 2 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 2 2 2]\n",
      "Cluster Labels for 7 PCA components and 5 clusters: [0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 1 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 1 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 3 3 3 3 1 2 2 0 2 2 0\n",
      " 0 0 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 2 0 1 1\n",
      " 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 2 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0 0\n",
      " 0 0 0 0 4 0 0 2 0 0 0 2 0 0 0 1 1 0 0 1 1 4 4 1 2 4 4 4 4 4 4 4 1 1 4 4 1\n",
      " 4 1 1 1 4 0 0 0 0 0 4 4 4 4 0 0 1 1 1 1 1 4 4 1 1 1 1 1 1 1 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 0 4 4 4 0 4 4 4 4 0 0 0 4 1 1 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 0 1 1 0 0 1 0 0 0 2 0 0 2 0 0 2 2\n",
      " 0 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4\n",
      " 4 4 4 4 4 4 4 4 4 4 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1\n",
      " 2 2 0 0 2 2 2 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 2\n",
      " 2 0 2 0 0 0 0 0 0 1 0 0 0 0 0 0 2 1 1 1 1 1 0 0 0 2 2 0 0 1 0 2 2 2 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 0 0 2 2 2 0 0 0 0 0 2 2 2 0 2 2 2 0 2 2 0 2 2 2 2 2 2 2 0 2 2 2 2 1 2 2\n",
      " 2 2 2 2 2 2 2 0 2 2 2 2 0 2 2 2 0 2 2 0 2 0 2 0 2 2 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 2 2 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 2 2 0 0 1 2 2]\n",
      "Cluster Labels for 7 PCA components and 10 clusters: [1 1 1 1 1 8 1 1 1 8 8 8 0 4 4 3 4 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 4 0 4 8 7 0 0 8 4 8 2 2 2 2 2 4 6 0 0 4 8\n",
      " 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 8 2 2 2 0 1 1 1 8 1 0 0 0 1 8 8 4 8 3 3\n",
      " 3 3 3 3 3 3 3 1 8 3 3 1 1 3 3 4 1 1 1 1 3 1 1 1 1 1 1 1 3 3 1 1 6 7 1 1 1\n",
      " 1 1 1 1 0 1 8 4 1 1 8 8 8 1 1 5 5 1 6 6 5 6 6 6 6 6 6 9 9 9 9 9 6 5 9 6 5\n",
      " 9 5 5 5 1 1 1 1 1 0 9 9 9 0 0 0 3 7 7 7 7 7 7 7 7 7 7 7 7 6 6 6 6 6 6 6 6\n",
      " 6 9 9 5 7 7 7 9 9 9 9 9 9 9 9 9 6 6 6 6 1 9 9 9 0 0 0 0 0 0 1 0 7 7 7 7 7\n",
      " 6 9 9 9 9 9 9 9 9 9 9 9 9 0 0 0 9 9 9 0 0 3 3 1 1 3 1 1 8 4 8 1 4 8 8 4 4\n",
      " 1 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 3 3 3 3 1 1 1 1 1 1 1 1 1 1 8 8 1 1 1 1 0\n",
      " 7 7 6 9 9 9 9 9 9 0 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 1 3 3 3 7 7 3 3 1 1 3\n",
      " 4 3 1 1 4 6 6 1 1 1 3 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 8 4 1 1 1 1 1 8 4 8\n",
      " 8 8 8 1 1 1 1 1 1 3 1 1 1 1 1 1 3 6 3 3 3 3 1 8 1 6 4 1 1 3 1 8 4 4 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 8 1 1 1 1 1 1 1 1 8 1 1 1 0 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 8 8 8 4 4 8 8 1 1 1 8 6 8 4 8 4 8 8 8 4 4 8 4 8 4 4 4 4 4 8 4 4 4 4 3 4 4\n",
      " 4 4 4 4 8 8 4 8 8 8 4 4 1 4 4 4 6 4 4 8 4 8 8 8 4 8 1 1 1 1 1 1 1 8 8 1 1\n",
      " 8 8 8 8 1 1 1 3 3 3 3 3 3 3 3 3 3 3 4 4 8 1 3 4 6]\n",
      "Cluster Labels for 19 PCA components and 3 clusters: [1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 2 1 2 2 2 1 2 1 0 0 0 0 0 2 2 1 2 2 1\n",
      " 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 2\n",
      " 2 2 2 2 2 2 2 1 1 2 2 1 1 2 2 2 1 1 1 1 2 1 1 1 1 1 1 1 2 2 1 1 2 2 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 1 1 1 1 1 1 2 2 2 2 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 1 1 2 1 1 1 1 1 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 2 2 2 1 1 2 2 1 1 2 1 1 1 2 1 1 2 1 1 2 2\n",
      " 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 1 2\n",
      " 2 2 1 1 2 2 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 1\n",
      " 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 2 2 2 2 2 1 1 1 2 2 1 1 2 1 1 2 2 1 1 1\n",
      " 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 1 1 1 2 2 1 1 1 1 1 1 1 1 2 1 2 1 1 1 2 2 1 1 1 2 2 2 2 2 1 2 2 2 2 2 2 2\n",
      " 2 2 2 2 1 1 1 1 1 1 2 1 1 2 2 2 1 2 2 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 2 2 2]\n",
      "Cluster Labels for 19 PCA components and 5 clusters: [0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 1 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 3 3 0 3 3 0\n",
      " 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 0 0 0 0 0 0 0 0 0 0 0 0 3 0 1 1\n",
      " 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 3 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0 0\n",
      " 0 0 0 0 0 0 0 3 0 0 0 3 0 0 0 1 1 0 0 1 1 1 4 1 1 4 4 4 4 4 4 4 1 1 4 4 1\n",
      " 4 1 1 1 0 0 0 0 0 0 4 4 4 4 0 0 1 1 1 1 1 4 4 1 1 1 1 1 1 1 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 0 4 4 4 0 4 4 4 4 0 0 0 4 1 1 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 0 1 1 0 0 1 0 0 0 3 0 0 3 0 0 3 3\n",
      " 0 1 1 1 1 1 1 1 1 1 1 1 1 1 3 3 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4\n",
      " 4 4 4 4 4 4 4 4 4 4 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1\n",
      " 3 3 0 0 3 3 3 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 3 3\n",
      " 3 0 3 0 0 0 0 0 0 1 0 0 0 0 0 0 3 1 1 1 1 1 0 0 0 3 3 0 0 1 0 3 3 3 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 0 0 3 3 3 0 0 0 0 0 3 3 3 0 3 3 3 0 3 3 0 3 3 3 3 3 3 3 0 3 3 3 3 1 3 3\n",
      " 3 3 3 3 3 3 3 0 3 3 3 3 0 3 3 3 0 3 3 0 3 0 3 0 3 3 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 3 3 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 3 3 0 0 1 3 1]\n",
      "Cluster Labels for 19 PCA components and 10 clusters: [0 0 8 0 8 0 8 8 8 8 0 0 0 1 1 9 9 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 1 3 1 8 3 3 3 8 9 8 4 4 4 4 4 1 1 3 3 5 0\n",
      " 0 8 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 8 4 4 4 0 0 8 8 8 8 0 0 8 0 0 8 9 8 9 9\n",
      " 9 9 9 9 9 9 9 0 0 9 9 0 0 1 1 1 0 0 0 0 9 0 0 0 0 8 8 8 9 9 0 0 8 3 8 0 0\n",
      " 0 8 8 8 7 8 5 5 8 8 8 5 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 7 7 7 7 7 1 9 7 7 9\n",
      " 7 1 1 1 8 8 0 0 0 0 7 7 7 7 3 0 9 3 3 3 3 3 3 3 3 3 3 3 3 1 1 1 1 7 7 7 1\n",
      " 1 7 7 7 3 1 3 7 7 7 7 7 7 7 7 7 7 1 1 1 0 7 7 7 3 7 3 7 3 3 0 0 3 3 3 3 3\n",
      " 1 7 7 7 7 7 7 7 7 7 7 7 7 7 7 3 7 7 7 7 3 9 9 8 0 9 8 0 8 5 0 0 5 0 0 5 5\n",
      " 0 9 9 9 9 9 9 9 9 9 9 9 9 9 9 5 9 9 9 9 0 0 0 0 0 0 0 8 8 0 8 8 8 8 0 0 0\n",
      " 1 1 1 7 7 7 7 7 7 7 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 9 9 9 9 9 9 9 0 0 9\n",
      " 1 9 0 8 1 1 1 0 0 0 8 8 0 0 8 0 0 8 8 0 0 8 8 8 0 0 8 0 5 8 8 8 8 8 8 5 5\n",
      " 5 0 5 0 0 8 8 8 8 9 8 0 0 0 0 0 9 1 9 9 9 9 0 0 0 1 9 0 8 9 0 5 9 9 0 8 8\n",
      " 0 0 0 8 8 8 0 8 8 0 8 8 0 0 8 8 0 0 8 8 8 8 8 0 0 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 0 0 0 5 5 5 0 0 8 8 8 8 5 5 8 5 5 5 5 5 5 5 5 5 5 5 5 5 5 8 5 5 5 5 8 5 5\n",
      " 5 5 5 5 5 5 5 8 5 5 5 5 8 5 5 5 8 5 5 5 5 5 8 8 5 5 0 8 8 8 8 8 8 8 0 0 0\n",
      " 0 5 5 5 0 0 8 9 9 6 9 6 9 9 9 6 9 9 1 9 0 0 9 5 1]\n",
      "Cluster Labels for 132 PCA components and 3 clusters: [0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 2 0 2 2 2 0 1 0 1 1 1 1 1 1 2 0 0 1 0\n",
      " 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1\n",
      " 1 1 1 1 1 1 1 0 0 1 1 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 2 2 1 2 2 2 2 2 2 2 2 1 1 2 2 1\n",
      " 2 1 1 1 0 0 0 0 0 0 2 2 2 2 2 0 1 2 1 2 2 2 2 1 1 1 1 2 2 0 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 0 0 0 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 0 0 1 0 0 0 1 0 0 0 0 0 1 1\n",
      " 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2\n",
      " 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1\n",
      " 1 0 0 0 1 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 0 0 1 0 0 1 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 1 1 1 1 1 0 1 1 1 0 1 1 1\n",
      " 1 1 1 1 0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1]\n",
      "Cluster Labels for 132 PCA components and 5 clusters: [0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 3 1 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 1 1 1 1 1 1 1 1 1 1 4 4 4 4 4 1 1 0 1 1 0\n",
      " 0 0 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 0 4 4 4 0 0 0 0 0 0 0 0 0 0 0 0 1 1 3 3\n",
      " 3 3 3 3 3 3 3 0 0 3 3 0 0 3 3 1 0 0 0 0 3 0 0 0 0 0 0 0 3 3 0 0 3 3 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 3 3 0 0 3 3 3 2 3 3 3 2 2 2 2 2 2 3 3 2 2 3\n",
      " 2 3 3 3 0 0 0 0 0 0 2 2 2 2 0 0 3 3 3 3 3 2 2 3 3 3 3 3 3 3 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 0 2 2 2 2 0 0 0 2 3 3 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 3 3 0 0 3 0 0 0 1 0 0 1 0 0 1 1\n",
      " 0 3 3 3 3 3 3 3 3 3 3 3 3 3 1 1 3 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2\n",
      " 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 0 3 3 3 3 3 3 3 0 0 3\n",
      " 1 1 0 0 1 1 1 0 0 0 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1\n",
      " 1 0 1 0 0 0 0 0 0 3 0 0 0 0 0 0 3 3 3 3 3 3 0 0 0 1 1 0 0 3 0 1 1 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 0 0 0 1 1 1 0 0 0 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 3 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 1 0 0 0 0 3 3 3 3 3 3 3 3 3 3 3 1 1 0 0 3 1 3]\n",
      "Cluster Labels for 132 PCA components and 10 clusters: [1 1 1 1 8 8 1 1 1 8 8 8 8 7 7 4 7 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 8 8 8 8 8 8 8 8 7 8 3 3 3 3 3 8 8 8 8 7 8\n",
      " 8 8 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 8 3 3 3 1 1 1 1 8 1 8 1 8 1 8 8 7 8 4 4\n",
      " 4 4 4 4 4 4 4 1 1 4 4 1 1 1 4 7 1 1 1 1 4 1 1 1 1 1 1 1 4 4 1 1 1 9 1 1 1\n",
      " 1 1 1 1 2 1 8 8 1 1 8 8 1 1 1 5 5 1 5 5 5 5 5 5 5 5 5 5 2 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 1 1 1 1 1 1 2 2 2 2 9 1 4 9 9 9 9 9 9 9 9 9 9 9 9 1 2 5 2 5 5 5 2\n",
      " 2 2 2 5 9 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 9 1 1 9 9 9 9 9\n",
      " 2 2 2 5 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 9 4 4 1 1 4 1 1 8 7 8 1 7 1 8 7 7\n",
      " 1 4 4 4 4 4 4 4 4 4 4 4 4 4 7 7 4 4 4 4 1 1 1 1 1 1 1 1 1 1 8 1 1 1 1 1 1\n",
      " 2 2 2 2 2 2 2 2 2 2 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 1 4 4 4 4 4 4 4 1 1 4\n",
      " 7 7 1 1 7 7 7 1 1 1 4 4 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 7 1 1 1 1 1 8 7 8\n",
      " 8 8 8 1 1 1 1 1 1 4 1 1 1 1 1 1 7 7 4 4 4 4 1 8 1 7 7 1 1 4 1 8 7 7 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 8 1 1 1 1 1 1 1 1 8 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 8 8 8 7 7 8 8 1 1 1 8 1 8 7 8 7 8 8 8 7 7 8 8 8 7 7 7 7 7 8 7 7 7 7 8 7 7\n",
      " 7 7 7 7 8 8 8 8 8 8 8 8 1 7 7 7 8 7 7 8 7 8 8 1 7 8 1 1 1 1 1 1 1 8 1 1 1\n",
      " 8 8 8 8 1 1 1 4 0 0 0 0 0 4 0 0 4 7 7 7 1 1 4 7 7]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "# Step 1: Inspect Cluster Labels\n",
    "# Count the occurrences of each label in the last cluster_labels variable\n",
    "# (for the last set of PCA components and k clusters)\n",
    "cluster_label_count = Counter(cluster_labels)\n",
    "print(\"Cluster Label Distribution:\", cluster_label_count)\n",
    "\n",
    "# Step 2: Examine Closest Texts to Centroids\n",
    "# Display some of the texts closest to each centroid, for both original and paraphrased\n",
    "for i, (orig_cluster, para_cluster) in enumerate(zip(closest_text_to_centers, paraphrased_text_to_centers)):\n",
    "    print(f\"Cluster {i} - Original Texts: {orig_cluster}\")\n",
    "    print(f\"Cluster {i} - Paraphrased Texts: {para_cluster}\")\n",
    "\n",
    "# Step 3: Evaluate Paraphrasing\n",
    "# Manually compare some original texts with their paraphrased versions\n",
    "print(\"Manually compare the original and paraphrased texts displayed above.\")\n",
    "\n",
    "# Step 4: Variability Across Different PCA and K-means Settings\n",
    "# For simplicity, let's just print out the cluster labels for each setting\n",
    "print(\"\\nStep 4: Variability Across Different PCA and K-means Settings\")\n",
    "for num_components in pca_components:\n",
    "    pca = PCA(n_components=num_components)\n",
    "    embeddings_pca = pca.fit_transform(embeddings_scaled)\n",
    "    for k in k_values:\n",
    "        kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "        kmeans.fit(embeddings_pca)\n",
    "        print(f\"Cluster Labels for {num_components} PCA components and {k} clusters: {kmeans.labels_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa994ae5-18d4-4736-a529-79f329ff1034",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
